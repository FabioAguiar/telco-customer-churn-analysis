{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b360890a",
   "metadata": {},
   "source": [
    "# Prepara√ß√£o de Dados (N1)\n",
    "\n",
    "## üóÇÔ∏è [ Projeto ]\n",
    "\n",
    "**Nome do Projeto:** [nome do projeto]  \n",
    "**Dataset:** [Nome do dataset ou fonte de dados]  \n",
    "**Objetivo Geral:** [Breve Explica√ß√£o do prop√≥sito ‚Äî ex.: ‚ÄúAnalisar o comportamento de churn e identificar fatores de reten√ß√£o de clientes.‚Äù]  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã Descri√ß√£o Geral do Tratamento\n",
    "\n",
    "Nesta etapa ser√£o realizados os principais **processos de limpeza, transforma√ß√£o e padroniza√ß√£o dos dados**.  \n",
    "O foco √© garantir que o dataset esteja **consistente, estruturado e pronto para an√°lises posteriores**.\n",
    "\n",
    "**Tarefas previstas:**  \n",
    "- Leitura e diagn√≥stico inicial do dataset.  \n",
    "- Tratamento de valores nulos, duplicados e outliers.  \n",
    "- Convers√£o de tipos e padroniza√ß√£o de nomes de colunas.  \n",
    "- Codifica√ß√£o de vari√°veis categ√≥ricas e normaliza√ß√£o de num√©ricas (quando necess√°rio).  \n",
    "- Gera√ß√£o de artefatos intermedi√°rios e relat√≥rio de qualidade dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91f747",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o do Projeto (Bootstrap)\n",
    "\n",
    "Esta etapa realiza o **bootstrap do ambiente de execu√ß√£o**, preparando o notebook para funcionar em qualquer m√°quina ‚Äî garantindo **reprodutibilidade**, **organiza√ß√£o** e **autonomia**.  \n",
    "Todas as depend√™ncias, caminhos e configura√ß√µes s√£o ajustadas automaticamente, sem necessidade de modifica√ß√µes manuais.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Etapas realizadas\n",
    "\n",
    "#### üß≠ 1. Localiza√ß√£o da raiz do projeto  \n",
    "- Busca o arquivo `config/defaults.json` subindo diret√≥rios at√© encontr√°-lo.  \n",
    "- Define `PROJECT_ROOT` como ponto de refer√™ncia global para todos os caminhos do projeto.\n",
    "\n",
    "#### üß© 2. Valida√ß√£o da estrutura `utils/`  \n",
    "- Verifica se existem a pasta `utils/` e o arquivo `__init__.py` (criado automaticamente, se ausente).  \n",
    "- Garante que o pacote seja reconhecido pelo Python, permitindo importar `utils.utils_data` sem erros.\n",
    "\n",
    "#### üß± 3. Registro no `sys.path`  \n",
    "- Adiciona o diret√≥rio raiz (`PROJECT_ROOT`) ao `sys.path`, habilitando o uso de m√≥dulos internos em qualquer ambiente.  \n",
    "- Exibe o caminho detectado e o status do registro.\n",
    "\n",
    "#### ‚ôªÔ∏è 4. Importa√ß√£o e recarregamento das utilidades  \n",
    "- Importa o m√≥dulo `utils.utils_data` e o recarrega via `importlib.reload`.  \n",
    "- Essa abordagem assegura que o notebook use **sempre a vers√£o mais recente** do arquivo durante o desenvolvimento iterativo.\n",
    "\n",
    "#### üßæ 5. Inicializa√ß√£o do sistema de logs  \n",
    "- Cria um log unificado em `reports/data_preparation.log`.  \n",
    "- Cada etapa importante (carregamento, limpeza, exporta√ß√£o etc.) √© registrada tanto no **console** quanto em **arquivo**, facilitando a rastreabilidade do processo.\n",
    "\n",
    "#### ‚öôÔ∏è 6. Carregamento das configura√ß√µes globais  \n",
    "- L√™ os par√¢metros de `config/defaults.json` e, se existir, aplica substitui√ß√µes de `config/local.json`.  \n",
    "- Esses par√¢metros controlam o comportamento de cada etapa (tratamento de nulos, tipagem, outliers, encoding etc.).\n",
    "\n",
    "#### üìÇ 7. Resolu√ß√£o de diret√≥rios e arquivos padr√£o  \n",
    "- Garante a exist√™ncia das pastas principais:  \n",
    "  `data/raw`, `data/interim`, `data/processed`, `reports`, `artifacts`, `prints`, `dashboards`.  \n",
    "- Define os arquivos de sa√≠da padr√£o (interim e processed), mantendo compatibilidade entre notebooks.\n",
    "\n",
    "#### üîÑ 8. Ambiente reprodut√≠vel e consistente  \n",
    "- Define a semente aleat√≥ria (`RANDOM_SEED = 42`) para resultados reprodut√≠veis.  \n",
    "- Ajusta as op√ß√µes de exibi√ß√£o do pandas (`max_columns` e `display.width`) para uma visualiza√ß√£o mais confort√°vel.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Resultado esperado\n",
    "\n",
    "Ao final desta c√©lula:\n",
    "\n",
    "- O projeto √© **reconhecido automaticamente**, independentemente do ambiente de execu√ß√£o.  \n",
    "- O m√≥dulo `utils_data.py` √© importado com todas as fun√ß√µes utilit√°rias dispon√≠veis.  \n",
    "- As pastas e arquivos padr√£o s√£o criados e configurados.  \n",
    "- O log central come√ßa a registrar todas as a√ß√µes executadas nas pr√≥ximas etapas.  \n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:** Este design modular permite que o mesmo notebook seja executado em qualquer reposit√≥rio que siga a estrutura do template, sem ajustes manuais de caminho ou imports.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1233a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 04:59:57,546 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] sys.path ok. utils: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\n",
      "2025-11-04 04:59:57,554 | INFO | Bootstrap conclu√≠do.\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 04:59:57,556 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 04:59:57,557 | INFO | Config carregada e paths resolvidos.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Bootstrap do projeto ‚Äî encontra a raiz, injeta no sys.path e garante utils/__init__.py\n",
    "\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import random, numpy as np\n",
    "import json\n",
    "\n",
    "# 0) Raiz do projeto\n",
    "PROJECT_ROOT = ud.ensure_project_root()\n",
    "\n",
    "def _find_up(relative_path: str, start: Path | None = None) -> Path | None:\n",
    "    start = start or Path.cwd()\n",
    "    rel = Path(relative_path)\n",
    "    for base in (start, *start.parents):\n",
    "        cand = base / rel\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "# =========================================================\n",
    "# üé≤ Reprodutibilidade (seed global)\n",
    "# =========================================================\n",
    "RANDOM_SEED = config.get(\"random_seed\", 42)\n",
    "\n",
    "import numpy as np, random, os\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_SEED)\n",
    "\n",
    "# (opcional) se usar PyTorch/TF no futuro:\n",
    "# import torch\n",
    "# torch.manual_seed(RANDOM_SEED)\n",
    "# torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "\n",
    "\n",
    "# 1) Descobrir a raiz a partir do config/defaults.json\n",
    "_cfg = _find_up(\"config/defaults.json\")\n",
    "if _cfg is None:\n",
    "    raise FileNotFoundError(\"config/defaults.json n√£o encontrado. Confirme a estrutura do projeto.\")\n",
    "PROJECT_ROOT = _cfg.parent.parent.resolve()\n",
    "print(f\"[INFO] PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "\n",
    "# 2) Garantir pasta utils/ e __init__.py\n",
    "UTILS_DIR = PROJECT_ROOT / \"utils\"\n",
    "INIT_FILE = UTILS_DIR / \"__init__.py\"\n",
    "if not UTILS_DIR.exists():\n",
    "    raise ModuleNotFoundError(f\"Pasta n√£o encontrada: {UTILS_DIR} (crie 'utils' na raiz).\")\n",
    "if not INIT_FILE.exists():\n",
    "    INIT_FILE.write_text(\"\", encoding=\"utf-8\")\n",
    "    print(f\"[INFO] Criado: {INIT_FILE}\")\n",
    "\n",
    "# 3) Injetar a raiz no sys.path\n",
    "root_str = str(PROJECT_ROOT)\n",
    "if root_str not in sys.path:\n",
    "    sys.path.insert(0, root_str)\n",
    "print(f\"[INFO] sys.path ok. utils: {UTILS_DIR}\")\n",
    "\n",
    "# 4) Importar utils.utils_data\n",
    "import utils.utils_data as ud\n",
    "importlib.reload(ud)  # garante vers√£o mais recente ao iterar no notebook\n",
    "\n",
    "# 5) Configurar logging base do notebook\n",
    "LOG_FILE = (PROJECT_ROOT / \"reports\" / \"data_preparation.log\")\n",
    "LOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler(LOG_FILE, encoding=\"utf-8\")],\n",
    "    force=True,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Bootstrap conclu√≠do.\")\n",
    "\n",
    "# 6) Carregar configura√ß√µes\n",
    "config = ud.load_config(PROJECT_ROOT / \"config\" / \"defaults.json\",\n",
    "                        PROJECT_ROOT / \"config\" / \"local.json\")\n",
    "\n",
    "paths = ud.resolve_n1_paths(PROJECT_ROOT)             \n",
    "\n",
    "# 7) Seed e display (substitui ud.set_random_seed / ud.set_display)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "logger.info(\"Config carregada e paths resolvidos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3f035-806c-4803-9fc1-2b549c317fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15c3b97c-5cc9-41d4-b535-b806e2df2e0b",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o de Fontes\n",
    "\n",
    "Nesta etapa s√£o definidos os **arquivos de origem** que servir√£o de base para o projeto.  \n",
    "Aqui voc√™ informa **quais datasets ser√£o utilizados**, **em qual formato** est√£o (CSV ou Parquet) e, se houver mais de uma fonte, **como elas se relacionam**.\n",
    "\n",
    "---\n",
    "\n",
    "### üóÇÔ∏è 1. Explora√ß√£o das fontes dispon√≠veis\n",
    "\n",
    "Antes de configurar o dicion√°rio `SOURCES`, √© poss√≠vel listar os arquivos presentes no diret√≥rio `data/raw/`:\n",
    "\n",
    "```python\n",
    "from utils.utils_data import suggest_source_path, path_of\n",
    "\n",
    "RAW_DIR = paths.raw_dir\n",
    "suggest_source_path(RAW_DIR, pattern=\"*.csv\")\n",
    "```\n",
    "\n",
    "Esse comando exibe uma tabela com os arquivos encontrados e gera uma **sugest√£o autom√°tica de caminho** para copiar e colar no `SOURCES`.  \n",
    "Basta arrastar o arquivo para a pasta `data/raw/` e executar o bloco ‚Äî o nome aparecer√° pronto para uso.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 2. Defini√ß√£o das fontes de dados (`SOURCES`)\n",
    "\n",
    "- Cada entrada do dicion√°rio `SOURCES` representa uma tabela nomeada.  \n",
    "- A chave (ex.: `\"main\"`, `\"dim_customers\"`) identifica a tabela no projeto.  \n",
    "- Cada item cont√©m:\n",
    "  - `path`: caminho do arquivo dentro de `data/raw/`.  \n",
    "  - `format`: formato opcional (`\"csv\"` ou `\"parquet\"`). Se omitido, o formato √© detectado automaticamente.  \n",
    "  - `read_opts`: par√¢metros de leitura personalizados (`encoding`, `sep`, `low_memory`, etc.).\n",
    "\n",
    "Exemplo de estrutura:\n",
    "```python\n",
    "SOURCES = {\n",
    "    \"main\": {\n",
    "        \"path\": RAW_DIR / \"dataset.csv\",\n",
    "        \"read_opts\": {\"encoding\": \"utf-8\", \"sep\": \",\", \"low_memory\": False}\n",
    "    },\n",
    "    # Exemplo de segunda fonte em CSV:\n",
    "    # \"dim_customers\": {\n",
    "    #     \"path\": RAW_DIR / \"exemplo.csv\",\n",
    "    #     \"format\": \"csv\"\n",
    "    # }\n",
    "    # Exemplo de fonte em Parquet:\n",
    "    # \"dim_customers\": {\n",
    "    #     \"path\": RAW_DIR / \"customers.parquet\",\n",
    "    #     \"format\": \"parquet\"\n",
    "    # }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîó 3. Configura√ß√£o opcional de jun√ß√µes (`MERGE_STEPS`)\n",
    "\n",
    "O DataFrame principal √© o definido em `MAIN_SOURCE` (geralmente `\"main\"`).  \n",
    "Se existirem outras fontes, voc√™ pode configur√°-las em `MERGE_STEPS` para realizar merges autom√°ticos:\n",
    "\n",
    "```python\n",
    "MAIN_SOURCE = \"main\"\n",
    "MERGE_STEPS = [\n",
    "    # (\"dim_customers\", \"left\", \"customer_id\", \"id\"),\n",
    "]\n",
    "```\n",
    "\n",
    "Cada item define:\n",
    "- o nome da tabela secund√°ria (`right_name`),\n",
    "- o tipo de jun√ß√£o (`how`),\n",
    "- e as chaves de correspond√™ncia (`left_on`, `right_on`).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 4. Valida√ß√£o e feedback autom√°tico\n",
    "\n",
    "Ap√≥s definir as fontes, o bloco final realiza uma checagem simples:\n",
    "\n",
    "- Confirma se o arquivo principal existe.  \n",
    "- Detecta automaticamente o formato (`CSV` ou `Parquet`).  \n",
    "- Exibe mensagens de status amig√°veis:\n",
    "\n",
    "```\n",
    "‚úÖ Fontes configuradas com sucesso.\n",
    "‚Üí Fonte principal: 'main'  | Arquivo: dataset.csv  | Formato detectado: CSV\n",
    "‚Üí Nenhum merge configurado (usando apenas a fonte principal).\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> üí° Resumo\n",
    ">\n",
    ">Essa abordagem torna a **configura√ß√£o de fontes interativa, leve e flex√≠vel**:\n",
    ">- Basta colocar novos arquivos em `data/raw/` e usar `suggest_source_path()` para gerar o caminho.  \n",
    ">- N√£o h√° necessidade de alterar outros blocos do notebook ‚Äî apenas o `SOURCES` e, se necess√°rio, os merges.  \n",
    ">- Ideal para projetos explorat√≥rios e notebooks reutiliz√°veis em diferentes datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "681bf24a-8f54-42eb-8e41-3854c616d924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [suggest_source_path] 1 arquivo(s) encontrados; exibindo 1.\n",
      "2025-11-04 04:59:59,213 | INFO | [suggest_source_path] 1 arquivo(s) encontrados; exibindo 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\fabio\\Projetos DEV\\data projects\\data...</td>\n",
       "      <td>dataset.csv</td>\n",
       "      <td>977501</td>\n",
       "      <td>2019-09-27T19:30:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path         name  size_bytes  \\\n",
       "0  C:\\Users\\fabio\\Projetos DEV\\data projects\\data...  dataset.csv      977501   \n",
       "\n",
       "              modified  \n",
       "0  2019-09-27T19:30:08  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, importlib\n",
    "sys.path.insert(0, r\"C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\")\n",
    "import importlib, utils_data as ud\n",
    "importlib.reload(ud)\n",
    "\n",
    "RAW_DIR = paths.raw_dir\n",
    "ud.suggest_source_path(RAW_DIR, pattern=\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58848935-7ea0-4afd-956c-c5181584c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fontes configuradas com sucesso.\n",
      "‚Üí Fonte principal: 'main'  | Arquivo: dataset.csv  | Formato detectado: CSV\n",
      "‚Üí Nenhum merge configurado (usando apenas a fonte principal).\n"
     ]
    }
   ],
   "source": [
    "# Obs: s√≥ alterar este bloco quando precisar mudar os arquivos ou as chaves de jun√ß√£o.\n",
    "\n",
    "SOURCES = {\n",
    "    # nome_da_tabela: {path, (opcional) format: 'csv'|'parquet', (opcional) read_opts}\n",
    "    \"main\": {\n",
    "        \"path\": RAW_DIR / \"dataset.csv\",\n",
    "        # \"format\": \"csv\",  # se omitir, detecta pelo sufixo\n",
    "        \"read_opts\": {\"encoding\": \"utf-8\", \"sep\": \",\", \"low_memory\": False}\n",
    "    },\n",
    "    # Exemplo de segunda fonte em CSV:\n",
    "    # \"dim_customers\": {\n",
    "    #   \"path\": RAW_DIR / \"exemplo.csv\",\n",
    "    #   \"format\": \"csv\",  # se omitir, detecta pelo sufixo\n",
    "    #   \"read_opts\": {\"encoding\": \"utf-8\", \"sep\": \",\", \"low_memory\": False}\n",
    "    # }\n",
    "    \n",
    "    # Exemplo de fonte em Parquet:\n",
    "    # \"dim_customers\": {\n",
    "    #     \"path\": RAW_DIR / \"customers.parquet\",\n",
    "    #     \"format\": \"parquet\"\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Plano de merges (opcional):\n",
    "# Cada item √© um passo: (right_name, how, left_on, right_on)\n",
    "# O DataFrame base ser√° o SOURCES[MAIN_SOURCE]\n",
    "MAIN_SOURCE = \"main\"\n",
    "MERGE_STEPS = [\n",
    "    # (\"dim_customers\", \"left\", \"customer_id\", \"id\"),\n",
    "]\n",
    "\n",
    "# Valida√ß√£o\n",
    "main_path = SOURCES[MAIN_SOURCE][\"path\"]\n",
    "main_format = SOURCES[MAIN_SOURCE].get(\"format\") or main_path.suffix.lstrip(\".\").lower()\n",
    "print(f\"‚úÖ Fontes configuradas com sucesso.\")\n",
    "\n",
    "print(\n",
    "    f\"‚Üí Fonte principal: '{MAIN_SOURCE}'  \"\n",
    "    f\"| Arquivo: {main_path.name}  \"\n",
    "    f\"| Formato detectado: {main_format.upper()}\"\n",
    ")\n",
    "if MERGE_STEPS:\n",
    "    print(f\"‚Üí {len(MERGE_STEPS)} etapa(s) de merge configuradas.\")\n",
    "else:\n",
    "    print(\"‚Üí Nenhum merge configurado (usando apenas a fonte principal).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0a7c4-a99e-4eca-baab-b3d8a6a149ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7aca992",
   "metadata": {},
   "source": [
    "## üì• Ingest√£o & Vis√£o R√°pida\n",
    "\n",
    "Nesta etapa, os **datasets definidos em `SOURCES`** s√£o carregados, inspecionados e validados antes de iniciar o tratamento dos dados.  \n",
    "O objetivo √© garantir que as fontes estejam corretamente lidas e que o DataFrame principal (`df`) esteja pronto para seguir no pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 1. Carregamento das fontes\n",
    "\n",
    "Cada item de `SOURCES` √© percorrido para:\n",
    "- Ler o arquivo indicado (`path`) conforme o formato (`csv` ou `parquet`);  \n",
    "- Aplicar as op√ß√µes de leitura (`read_opts`) definidas no dicion√°rio;  \n",
    "- Armazenar o DataFrame em `tables[name]`, onde `name` √© a chave de identifica√ß√£o da fonte.\n",
    "\n",
    "A fun√ß√£o utilizada √© `ud.load_table_simple()`, que automaticamente:\n",
    "- Detecta o formato pelo sufixo (se n√£o informado);\n",
    "- Aplica `read_opts` de forma segura;\n",
    "- Exibe logs amig√°veis durante o carregamento.\n",
    "\n",
    "Ap√≥s cada leitura, √© exibido um **resumo r√°pido** da fonte carregada, com:\n",
    "- N√∫mero de linhas e colunas;\n",
    "- Tipos de dados;\n",
    "- Uso de mem√≥ria;\n",
    "- E um relat√≥rio de valores nulos (`ud.missing_report()`).\n",
    "\n",
    "---\n",
    "\n",
    "### üîó 2. Defini√ß√£o do DataFrame base e jun√ß√µes opcionais\n",
    "\n",
    "O dataset principal √© definido pela vari√°vel `MAIN_SOURCE`.  \n",
    "Caso existam outras fontes configuradas em `MERGE_STEPS`, o notebook aplica as jun√ß√µes automaticamente via `ud.merge_chain()` ‚Äî garantindo que cada passo do merge seja logado e validado.\n",
    "\n",
    "Se nenhuma jun√ß√£o for configurada, o notebook utiliza apenas a fonte principal.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 3. Vis√£o geral final do DataFrame\n",
    "\n",
    "Ap√≥s a etapa de ingest√£o e merges, o notebook gera uma vis√£o consolidada do dataset final (`df`) que seguir√° no pipeline.  \n",
    "S√£o exibidos:\n",
    "- Estrutura geral (`shape`, colunas, tipos);\n",
    "- Quantidade de valores nulos por coluna;\n",
    "- E um log detalhado gravado em `reports/data_preparation.log`.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Exemplo de estrutura do processo\n",
    "\n",
    "```python\n",
    "tables = {}\n",
    "for name, cfg in SOURCES.items():\n",
    "    path = cfg[\"path\"]\n",
    "    fmt = cfg.get(\"format\")\n",
    "    read_opts = cfg.get(\"read_opts\", {})\n",
    "    df_src = ud.load_table_simple(path, fmt, **read_opts)\n",
    "    tables[name] = df_src\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    ov = ud.basic_overview(df_src)\n",
    "    print(json.dumps(ov, indent=2, ensure_ascii=False))\n",
    "    display(ud.missing_report(df_src).head(20))\n",
    "\n",
    "# Base principal e merges\n",
    "df = tables[MAIN_SOURCE]\n",
    "if MERGE_STEPS:\n",
    "    df = ud.merge_chain(df, tables, MERGE_STEPS)\n",
    "else:\n",
    "    print(f\"[INFO] Usando df base: '{MAIN_SOURCE}' (sem merges).\")\n",
    "\n",
    "# Overview final\n",
    "overview = ud.basic_overview(df)\n",
    "logger.info(json.dumps(overview, indent=2, ensure_ascii=False))\n",
    "display(ud.missing_report(df).head(20))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> - Cada fonte de dados √© carregada automaticamente com base na configura√ß√£o do dicion√°rio `SOURCES`.  \n",
    "> - A fun√ß√£o `ud.load_table_simple()` lida tanto com arquivos CSV quanto Parquet e detecta o formato automaticamente.  \n",
    "> - O dicion√°rio `tables` mant√©m todas as fontes acess√≠veis pelo nome definido (ex.: `\"main\"`, `\"dim_customers\"`).  \n",
    "> - A vari√°vel `df` representa o dataset principal que seguir√° pelas pr√≥ximas etapas do pipeline.  \n",
    "> - Logs e relat√≥rios s√£o salvos para garantir transpar√™ncia e rastreabilidade do processo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9753997b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\\utils_data.py\n",
      "1.2.2-merged\n",
      "\n",
      "=== main ===\n",
      "{\n",
      "  \"rows\": 7043,\n",
      "  \"cols\": 21,\n",
      "  \"dtypes\": {\n",
      "    \"customerID\": \"object\",\n",
      "    \"gender\": \"object\",\n",
      "    \"SeniorCitizen\": \"int64\",\n",
      "    \"Partner\": \"object\",\n",
      "    \"Dependents\": \"object\",\n",
      "    \"tenure\": \"int64\",\n",
      "    \"PhoneService\": \"object\",\n",
      "    \"MultipleLines\": \"object\",\n",
      "    \"InternetService\": \"object\",\n",
      "    \"OnlineSecurity\": \"object\",\n",
      "    \"OnlineBackup\": \"object\",\n",
      "    \"DeviceProtection\": \"object\",\n",
      "    \"TechSupport\": \"object\",\n",
      "    \"StreamingTV\": \"object\",\n",
      "    \"StreamingMovies\": \"object\",\n",
      "    \"Contract\": \"object\",\n",
      "    \"PaperlessBilling\": \"object\",\n",
      "    \"PaymentMethod\": \"object\",\n",
      "    \"MonthlyCharges\": \"float64\",\n",
      "    \"TotalCharges\": \"object\",\n",
      "    \"Churn\": \"object\"\n",
      "  },\n",
      "  \"memory_mb\": 6.821\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthlyCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tenure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SeniorCitizen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  missing_count  missing_pct\n",
       "0         customerID              0          0.0\n",
       "1   DeviceProtection              0          0.0\n",
       "2       TotalCharges              0          0.0\n",
       "3     MonthlyCharges              0          0.0\n",
       "4      PaymentMethod              0          0.0\n",
       "5   PaperlessBilling              0          0.0\n",
       "6           Contract              0          0.0\n",
       "7    StreamingMovies              0          0.0\n",
       "8        StreamingTV              0          0.0\n",
       "9        TechSupport              0          0.0\n",
       "10      OnlineBackup              0          0.0\n",
       "11            gender              0          0.0\n",
       "12    OnlineSecurity              0          0.0\n",
       "13   InternetService              0          0.0\n",
       "14     MultipleLines              0          0.0\n",
       "15      PhoneService              0          0.0\n",
       "16            tenure              0          0.0\n",
       "17        Dependents              0          0.0\n",
       "18           Partner              0          0.0\n",
       "19     SeniorCitizen              0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Usando df base: 'main' (sem merges).\n",
      "2025-11-04 05:00:00,868 | INFO | {\n",
      "  \"rows\": 7043,\n",
      "  \"cols\": 21,\n",
      "  \"dtypes\": {\n",
      "    \"customerID\": \"object\",\n",
      "    \"gender\": \"object\",\n",
      "    \"SeniorCitizen\": \"int64\",\n",
      "    \"Partner\": \"object\",\n",
      "    \"Dependents\": \"object\",\n",
      "    \"tenure\": \"int64\",\n",
      "    \"PhoneService\": \"object\",\n",
      "    \"MultipleLines\": \"object\",\n",
      "    \"InternetService\": \"object\",\n",
      "    \"OnlineSecurity\": \"object\",\n",
      "    \"OnlineBackup\": \"object\",\n",
      "    \"DeviceProtection\": \"object\",\n",
      "    \"TechSupport\": \"object\",\n",
      "    \"StreamingTV\": \"object\",\n",
      "    \"StreamingMovies\": \"object\",\n",
      "    \"Contract\": \"object\",\n",
      "    \"PaperlessBilling\": \"object\",\n",
      "    \"PaymentMethod\": \"object\",\n",
      "    \"MonthlyCharges\": \"float64\",\n",
      "    \"TotalCharges\": \"object\",\n",
      "    \"Churn\": \"object\"\n",
      "  },\n",
      "  \"memory_mb\": 6.821\n",
      "}\n",
      "{\n",
      "  \"rows\": 7043,\n",
      "  \"cols\": 21,\n",
      "  \"dtypes\": {\n",
      "    \"customerID\": \"object\",\n",
      "    \"gender\": \"object\",\n",
      "    \"SeniorCitizen\": \"int64\",\n",
      "    \"Partner\": \"object\",\n",
      "    \"Dependents\": \"object\",\n",
      "    \"tenure\": \"int64\",\n",
      "    \"PhoneService\": \"object\",\n",
      "    \"MultipleLines\": \"object\",\n",
      "    \"InternetService\": \"object\",\n",
      "    \"OnlineSecurity\": \"object\",\n",
      "    \"OnlineBackup\": \"object\",\n",
      "    \"DeviceProtection\": \"object\",\n",
      "    \"TechSupport\": \"object\",\n",
      "    \"StreamingTV\": \"object\",\n",
      "    \"StreamingMovies\": \"object\",\n",
      "    \"Contract\": \"object\",\n",
      "    \"PaperlessBilling\": \"object\",\n",
      "    \"PaymentMethod\": \"object\",\n",
      "    \"MonthlyCharges\": \"float64\",\n",
      "    \"TotalCharges\": \"object\",\n",
      "    \"Churn\": \"object\"\n",
      "  },\n",
      "  \"memory_mb\": 6.821\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthlyCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tenure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SeniorCitizen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  missing_count  missing_pct\n",
       "0         customerID              0          0.0\n",
       "1   DeviceProtection              0          0.0\n",
       "2       TotalCharges              0          0.0\n",
       "3     MonthlyCharges              0          0.0\n",
       "4      PaymentMethod              0          0.0\n",
       "5   PaperlessBilling              0          0.0\n",
       "6           Contract              0          0.0\n",
       "7    StreamingMovies              0          0.0\n",
       "8        StreamingTV              0          0.0\n",
       "9        TechSupport              0          0.0\n",
       "10      OnlineBackup              0          0.0\n",
       "11            gender              0          0.0\n",
       "12    OnlineSecurity              0          0.0\n",
       "13   InternetService              0          0.0\n",
       "14     MultipleLines              0          0.0\n",
       "15      PhoneService              0          0.0\n",
       "16            tenure              0          0.0\n",
       "17        Dependents              0          0.0\n",
       "18           Partner              0          0.0\n",
       "19     SeniorCitizen              0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, importlib\n",
    "sys.path.insert(0, r\"C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\")\n",
    "\n",
    "import utils_data as ud\n",
    "importlib.reload(ud)\n",
    "\n",
    "print(ud.__file__)\n",
    "print(ud.UTILS_DATA_VERSION)  # deve mostrar 1.1.1\n",
    "\n",
    "\n",
    "# 1) Carregar todas as fontes\n",
    "tables = {}\n",
    "for name, cfg in SOURCES.items():\n",
    "    path = cfg[\"path\"]\n",
    "    fmt = cfg.get(\"format\")              # se None, detecta pelo sufixo\n",
    "    read_opts = cfg.get(\"read_opts\", {}) # ex.: sep/encoding/low_memory para CSV\n",
    "    df_src = ud.load_table_simple(path, fmt, **read_opts)  # agora com prefixo ud.\n",
    "    tables[name] = df_src\n",
    "\n",
    "    # vis√£o r√°pida por fonte\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    ov = ud.basic_overview(df_src)\n",
    "    print(json.dumps(ov, indent=2, ensure_ascii=False))\n",
    "    display(ud.missing_report(df_src).head(20))\n",
    "\n",
    "# 2) Definir df base e aplicar merges (se configurado)\n",
    "if MAIN_SOURCE not in tables:\n",
    "    raise KeyError(f\"MAIN_SOURCE '{MAIN_SOURCE}' n√£o encontrado. Fontes dispon√≠veis: {list(tables.keys())}\")\n",
    "\n",
    "df = tables[MAIN_SOURCE]\n",
    "if MERGE_STEPS:\n",
    "    df = ud.merge_chain(df, tables, MERGE_STEPS)\n",
    "    print(\"\\n=== Vis√£o geral (df merged) ===\")\n",
    "else:\n",
    "    print(f\"\\n[INFO] Usando df base: '{MAIN_SOURCE}' (sem merges).\")\n",
    "\n",
    "# 3) Overview final do df que segue no pipeline\n",
    "overview = ud.basic_overview(df)\n",
    "logger.info(json.dumps(overview, indent=2, ensure_ascii=False))\n",
    "print(json.dumps(overview, indent=2, ensure_ascii=False))\n",
    "display(ud.missing_report(df).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe738a9b-b6f3-4eaa-bfbe-13995efa7340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f132d3fd-de0e-4e93-9d3f-e5466a07b562",
   "metadata": {},
   "source": [
    "## üîñ Cat√°logo de DataFrames + df ‚Äúativo‚Äù\n",
    "\n",
    "Esta etapa cria um **cat√°logo centralizado de DataFrames** para gerenciar facilmente todas as tabelas carregadas e derivadas ao longo do projeto.  \n",
    "O objetivo √© permitir que diferentes vers√µes e transforma√ß√µes dos dados sejam armazenadas, nomeadas e acessadas de forma organizada e reprodut√≠vel.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 1. Inicializa√ß√£o do cat√°logo (`TableStore`)\n",
    "\n",
    "A classe `TableStore` (definida em `utils/utils_data.py`) atua como um **reposit√≥rio de DataFrames nomeados**.  \n",
    "Ela √© inicializada com o dicion√°rio `tables` (criado na etapa de *Ingest√£o & Vis√£o R√°pida*) e define a tabela principal (`MAIN_SOURCE`) como **tabela ativa**.\n",
    "\n",
    "Durante a inicializa√ß√£o, o notebook exibe uma mensagem de sucesso semelhante a esta:\n",
    "\n",
    "```\n",
    "‚úÖ Cat√°logo de DataFrames inicializado com sucesso.\n",
    "‚Üí Total de tabelas carregadas: 1\n",
    "‚Üí Tabela ativa: 'main'  | Shape: 7032 linhas √ó 21 colunas\n",
    "```\n",
    "\n",
    "E apresenta uma pr√©via do invent√°rio atual:\n",
    "\n",
    "| name | rows | cols | memory_mb |\n",
    "|------|------|-------|-----------|\n",
    "| main | 7032 | 21    | 1.2       |\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 2. Defini√ß√£o do DataFrame ativo (`df`)\n",
    "\n",
    "A vari√°vel `df` recebe a tabela atual atrav√©s de `T.get()`.  \n",
    "Esse `df` passa a representar o **DataFrame padr√£o** que seguir√° nas pr√≥ximas etapas do pipeline (limpeza, tipagem e transforma√ß√£o).\n",
    "\n",
    "---\n",
    "\n",
    "### üß© 3. Gerenciamento de m√∫ltiplas tabelas\n",
    "\n",
    "Novos DataFrames podem ser adicionados ao cat√°logo a qualquer momento, com nomes descritivos e controle de vers√£o.  \n",
    "O cat√°logo tamb√©m permite alternar entre tabelas e listar todas as dispon√≠veis.\n",
    "\n",
    "**Principais comandos:**\n",
    "\n",
    "```python\n",
    "T.add(\"churn_raw\", df, set_current=True)           # adiciona e define como atual\n",
    "df = T.use(\"churn_raw\")                            # alterna o df ativo\n",
    "T.add(\"features_v1\", engenharia_de_atributos(df))  # armazena uma nova deriva√ß√£o\n",
    "df_features = T[\"features_v1\"]                     # acesso direto por nome\n",
    "display(T.list())                                  # exibe o invent√°rio completo\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß† 4. Benef√≠cio pr√°tico\n",
    "\n",
    "- Mant√©m o notebook limpo e evita sobrescrever DataFrames importantes.  \n",
    "- Facilita o reuso e o rastreamento das vers√µes intermedi√°rias dos dados.  \n",
    "- Ideal para projetos com m√∫ltiplas fontes, transforma√ß√µes paralelas ou compara√ß√µes entre conjuntos tratados.  \n",
    "- Fornece feedback visual imediato sobre o estado do pipeline, tornando o fluxo mais transparente e interativo.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> O `TableStore` funciona como uma **mem√≥ria estruturada de DataFrames**, permitindo adicionar, alternar, versionar e consultar tabelas de forma controlada.  \n",
    "> A vari√°vel `df` representa sempre a **tabela ativa** atual, garantindo consist√™ncia nas etapas seguintes do pipeline e visibilidade sobre o progresso do processamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42d35c12-157e-4677-8b08-8cb6f9571ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cat√°logo de DataFrames inicializado com sucesso.\n",
      "‚Üí Total de tabelas carregadas: 1\n",
      "‚Üí Tabela ativa: 'main'  | Shape: 7043 linhas √ó 21 colunas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>memory_mb</th>\n",
       "      <th>current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>7043</td>\n",
       "      <td>21</td>\n",
       "      <td>6.821</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  rows  cols  memory_mb  current\n",
       "0  main  7043    21      6.821     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.utils_data import TableStore\n",
    "\n",
    "# 1- Inicializa cat√°logo com as fontes lidas ('tables') e define a base como atual\n",
    "T = TableStore(initial=tables, current=MAIN_SOURCE)\n",
    "\n",
    "# 2 - Conveni√™ncia: df = tabela atual (boa pr√°tica para seguir no pipeline)\n",
    "df = T.get()\n",
    "\n",
    "# 3 - Feedback visual de sucesso\n",
    "print(f\"‚úÖ Cat√°logo de DataFrames inicializado com sucesso.\")\n",
    "print(f\"‚Üí Total de tabelas carregadas: {len(tables)}\")\n",
    "print(f\"‚Üí Tabela ativa: '{T.current}'  | Shape: {df.shape[0]} linhas √ó {df.shape[1]} colunas\")\n",
    "\n",
    "# 4Ô∏è4 - Exibe uma pr√©via do cat√°logo\n",
    "display(T.list().head())\n",
    "\n",
    "# --- Guia r√°pido  ---\n",
    "# T.add(\"churn_raw\", df, set_current=True)          # cadastra e ativa\n",
    "# df = T.use(\"churn_raw\")                           # muda o atual e retorna df\n",
    "# T.add(\"features_v1\", engenharia_de_atributos(df)) # salva uma deriva√ß√£o\n",
    "# df_features = T[\"features_v1\"]                    # acesso direto por nome\n",
    "# display(T.list())                                 # invent√°rio das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d50f8-6e33-4e03-ab2d-b2cd97bd5af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "714e2ee7-bfcb-426b-80e3-eada5cd60941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "2                No             DSL            Yes          Yes   \n",
       "3  No phone service             DSL            Yes           No   \n",
       "4                No     Fiber optic             No           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "2               No          No          No              No  Month-to-month   \n",
       "3              Yes         Yes          No              No        One year   \n",
       "4               No          No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
       "0              Yes           Electronic check           29.85        29.85   \n",
       "1               No               Mailed check           56.95       1889.5   \n",
       "2              Yes               Mailed check           53.85       108.15   \n",
       "3               No  Bank transfer (automatic)           42.30      1840.75   \n",
       "4              Yes           Electronic check           70.70       151.65   \n",
       "\n",
       "  Churn  \n",
       "0    No  \n",
       "1    No  \n",
       "2   Yes  \n",
       "3    No  \n",
       "4   Yes  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23859a",
   "metadata": {},
   "source": [
    "## üß™ Qualidade & Tipagem\n",
    "\n",
    "Nesta etapa o notebook realiza a **padroniza√ß√£o estrutural e tipagem autom√°tica dos dados**, garantindo que o DataFrame principal (`df`) siga para as pr√≥ximas fases **coerente, limpo e otimizado em mem√≥ria**.  \n",
    "√â uma das fases mais cr√≠ticas do pipeline, pois evita que inconsist√™ncias de tipo e formato prejudiquem as an√°lises posteriores ou a modelagem.\n",
    "\n",
    "### üìã O que √© feito aqui\n",
    "\n",
    "1. **Remo√ß√£o de espa√ßos em branco (`strip_whitespace`)**\n",
    "   - Elimina espa√ßos extras no in√≠cio e no fim de valores textuais.  \n",
    "   - Evita diverg√™ncias em compara√ß√µes e agrupamentos (ex.: `\"Yes \"` ‚â† `\"Yes\"`).  \n",
    "   - Essa opera√ß√£o √© **idempotente**: se os dados j√° estiverem limpos, n√£o altera nada.\n",
    "\n",
    "2. **Convers√£o inteligente de valores num√©ricos (`infer_numeric_like`)**\n",
    "   - Detecta colunas com valores *aparentemente num√©ricos*, mas armazenados como texto (ex.: `\"R$ 120,00\"` ou `\"1.234,56\"`).  \n",
    "   - Aplica heur√≠sticas para remover s√≠mbolos, normalizar separadores e converter apenas quando a propor√ß√£o de convers√£o for suficiente (`min_ratio = 0.9`).  \n",
    "   - Evita convers√µes indevidas (ex.: IDs) por meio de uma lista de exclus√£o (`blacklist`).  \n",
    "   - Gera o relat√≥rio **`cast_report`**, registrando:\n",
    "     - Coluna analisada  \n",
    "     - A√ß√£o tomada (convertida, ignorada ou parcial)  \n",
    "     - Taxa de sucesso e total de valores convertidos.\n",
    "\n",
    "3. **Otimiza√ß√£o de tipos num√©ricos (`reduce_memory_usage`)**\n",
    "   - Converte automaticamente `int64` ‚Üí `int32` e `float64` ‚Üí `float32`, reduzindo o consumo de mem√≥ria sem alterar os valores.  \n",
    "   - O log mostra a diferen√ßa antes e depois (ex.: `Memory reduced: 7.76MB ‚Üí 6.21MB`).\n",
    "\n",
    "4. **Remo√ß√£o de duplicatas (`deduplicate_rows`)**\n",
    "   - Verifica e elimina registros repetidos conforme a configura√ß√£o (`subset`, `keep`).  \n",
    "   - Caso encontre duplicatas, gera um relat√≥rio detalhado e salva o log em `reports/duplicates.csv`.  \n",
    "   - Exibe uma amostra das duplicatas detectadas, se houver.\n",
    "\n",
    "5. **Relat√≥rios e feedback autom√°tico**\n",
    "   - Ao final da execu√ß√£o, exibe um resumo completo:  \n",
    "     - Linhas e colunas antes/depois  \n",
    "     - Varia√ß√£o de mem√≥ria (`Œî MB`)  \n",
    "     - Relat√≥rios gerados (`cast_report`, `duplicates_report`, etc.)  \n",
    "   - Todos os logs s√£o gravados em `reports/data_preparation.log`.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula garante que o dataset esteja **consistente, tipado e otimizado**, pronto para an√°lises e modelagem.  \n",
    "> Corrige formata√ß√µes, converte n√∫meros armazenados como texto, remove duplicatas e reduz o uso de mem√≥ria ‚Äî tudo com registros autom√°ticos e relat√≥rios salvos para auditoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43e16822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:01,947 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:01,962 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='n1_quality_typing:start' registrado.\n",
      "2025-11-04 05:00:01,967 | INFO | [manifest] step='n1_quality_typing:start' registrado.\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,145 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,149 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,162 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-04 05:00:02,166 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\cast_report.csv (18 linhas)\n",
      "2025-11-04 05:00:02,168 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\cast_report.csv (18 linhas)\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,170 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,182 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='n1_quality_typing:end' registrado.\n",
      "2025-11-04 05:00:02,186 | INFO | [manifest] step='n1_quality_typing:end' registrado.\n",
      "üìÑ Convers√µes num√©ricas (amostra):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>converted_non_null</th>\n",
       "      <th>introduced_nans</th>\n",
       "      <th>dtype_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>7032</td>\n",
       "      <td>11</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Churn</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  converted_non_null  introduced_nans dtype_after\n",
       "16      TotalCharges                7032               11     float64\n",
       "0         customerID                   0             7043      object\n",
       "1             gender                   0             7043      object\n",
       "15     PaymentMethod                   0             7043      object\n",
       "14  PaperlessBilling                   0             7043      object\n",
       "13          Contract                   0             7043      object\n",
       "12   StreamingMovies                   0             7043      object\n",
       "11       StreamingTV                   0             7043      object\n",
       "10       TechSupport                   0             7043      object\n",
       "9   DeviceProtection                   0             7043      object\n",
       "8       OnlineBackup                   0             7043      object\n",
       "7     OnlineSecurity                   0             7043      object\n",
       "6    InternetService                   0             7043      object\n",
       "5      MultipleLines                   0             7043      object\n",
       "4       PhoneService                   0             7043      object\n",
       "3         Dependents                   0             7043      object\n",
       "2            Partner                   0             7043      object\n",
       "17             Churn                   0             7043      object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Nenhuma duplicidade encontrada segundo os crit√©rios definidos.\n",
      "\n",
      "‚úÖ Qualidade & Tipagem conclu√≠do com sucesso!\n",
      "‚Üí Shape: (7043, 21) ‚Üí (7043, 21) (Œîlinhas=+0, Œîcolunas=+0)\n",
      "‚Üí Mem√≥ria: 6.82 MB ‚Üí 6.51 MB (Œî=-0.31 MB)\n",
      "‚Üí Relat√≥rios gerados: cast_report, df\n"
     ]
    }
   ],
   "source": [
    "# Qualidade & Tipagem (compat√≠vel com ambas as APIs)\n",
    "\n",
    "df_before_shape = df.shape\n",
    "mem_before = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "\n",
    "# ‚ö†Ô∏è Importante: N√ÉO passe paths.reports_dir como 'root', pois isso duplicar√° 'reports/reports'.\n",
    "# Deixe o utils resolver a raiz do projeto internamente.\n",
    "if hasattr(ud, \"n1_quality_typing_dict\"):\n",
    "    out = ud.n1_quality_typing_dict(df, config)   # sempre retorna dict\n",
    "    df  = out[\"df\"]\n",
    "    rep = out\n",
    "else:\n",
    "    df, rep = ud.n1_quality_typing(df, config)    # retorna (df, meta_dict)\n",
    "\n",
    "mem_after  = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "delta_rows = df.shape[0] - df_before_shape[0]\n",
    "delta_cols = df.shape[1] - df_before_shape[1]\n",
    "delta_mem  = mem_after - mem_before\n",
    "\n",
    "# Exibe relat√≥rios √∫teis (se existirem)\n",
    "cast_report = rep.get(\"cast_report\") if isinstance(rep, dict) else None\n",
    "if isinstance(cast_report, pd.DataFrame) and not cast_report.empty:\n",
    "    print(\"üìÑ Convers√µes num√©ricas (amostra):\")\n",
    "    display(cast_report.head(20))\n",
    "\n",
    "dups = rep.get(\"duplicates\") if isinstance(rep, dict) else None\n",
    "if isinstance(dups, pd.DataFrame) and not dups.empty:\n",
    "    print(\"\\nüîÅ Duplicatas detectadas (amostra):\")\n",
    "    display(dups.head(10))\n",
    "    dsum = rep.get(\"duplicates_summary\") if isinstance(rep, dict) else None\n",
    "    if isinstance(dsum, pd.DataFrame) and not dsum.empty:\n",
    "        print(\"üìä Resumo por chave:\")\n",
    "        display(dsum.head(20))\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nenhuma duplicidade encontrada segundo os crit√©rios definidos.\")\n",
    "\n",
    "# Mensagem de sucesso consolidada\n",
    "reported_keys = []\n",
    "if isinstance(rep, dict):\n",
    "    for k, v in rep.items():\n",
    "        if isinstance(v, pd.DataFrame) and not v.empty:\n",
    "            reported_keys.append(k)\n",
    "\n",
    "print(\n",
    "    f\"\\n‚úÖ Qualidade & Tipagem conclu√≠do com sucesso!\\n\"\n",
    "    f\"‚Üí Shape: {df_before_shape} ‚Üí {df.shape} (Œîlinhas={delta_rows:+}, Œîcolunas={delta_cols:+})\\n\"\n",
    "    f\"‚Üí Mem√≥ria: {mem_before:.2f} MB ‚Üí {mem_after:.2f} MB (Œî={delta_mem:+.2f} MB)\\n\"\n",
    "    f\"‚Üí Relat√≥rios gerados: {', '.join(reported_keys) if reported_keys else '‚Äî'}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8ee29-55cd-434e-afeb-3959c8ede4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b00dd1f3-27f8-402a-95da-b3faf39b0efc",
   "metadata": {},
   "source": [
    "## üßº Padroniza√ß√£o Categ√≥rica\n",
    "\n",
    "Nesta etapa ocorre a **padroniza√ß√£o global de r√≥tulos textuais** em colunas categ√≥ricas, corrigindo inconsist√™ncias, diferen√ßas de capitaliza√ß√£o e valores redundantes (como `\"No internet service\"` ‚Üí `\"No\"`).  \n",
    "O objetivo √© **garantir uniformidade sem alterar o significado dos dados**, preparando o dataset para codifica√ß√£o e modelagem.\n",
    "\n",
    "---\n",
    "\n",
    "### üìã O que √© feito aqui\n",
    "\n",
    "1. **Sele√ß√£o autom√°tica das colunas categ√≥ricas**  \n",
    "   - S√£o processadas todas as colunas com tipo `object`, `string` ou `category`, exceto aquelas listadas em `exclude` (ex.: `\"customerID\"`).\n",
    "\n",
    "2. **Limpeza e normaliza√ß√£o de forma**  \n",
    "   - Remove espa√ßos extras (`trim`) e consolida espa√ßos duplos (`collapse_ws`).  \n",
    "   - Corrige capitaliza√ß√£o conforme o par√¢metro `case` (`\"title\"`, `\"lower\"`, `\"upper\"`, `\"none\"`).  \n",
    "   - Opcionalmente remove acentos (`strip_accents`).\n",
    "\n",
    "3. **Substitui√ß√µes e valores nulos**  \n",
    "   - Aplica um mapa global de substitui√ß√µes (`global_map`) para corrigir padr√µes conhecidos (ex.: `\"No internet service\"` ‚Üí `\"No\"`).  \n",
    "   - Permite tamb√©m um mapa espec√≠fico por coluna (`per_column_map`), quando necess√°rio.  \n",
    "   - Converte valores definidos em `null_values` (ex.: `\"n/a\"`, `\"na\"`, `\"-\"`) em `NaN`.\n",
    "\n",
    "4. **Convers√£o opcional para categoria**  \n",
    "   - Se `cast_to_category=True`, converte colunas textuais em `category`, otimizando uso de mem√≥ria.\n",
    "\n",
    "5. **Gera√ß√£o de relat√≥rio e registro autom√°tico**  \n",
    "   - Cria o arquivo `cat_normalization.csv` dentro da pasta `reports/`, com:  \n",
    "     - Nome da coluna  \n",
    "     - Amostras antes/depois  \n",
    "     - Quantidade de altera√ß√µes (`changes`)  \n",
    "     - N√∫mero de categorias √∫nicas antes/depois  \n",
    "   - As informa√ß√µes tamb√©m s√£o registradas no log e adicionadas ao `manifest.json`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Configura√ß√£o (`CAT_NORM_CFG`)\n",
    "\n",
    "A padroniza√ß√£o √© controlada por um dicion√°rio de configura√ß√£o completo:\n",
    "\n",
    "```python\n",
    "CAT_NORM_CFG = {\n",
    "    \"enabled\": True,\n",
    "    \"exclude\": [\"customerID\"],\n",
    "    \"case\": \"title\",\n",
    "    \"strip_accents\": True,\n",
    "    \"collapse_ws\": True,\n",
    "    \"trim\": True,\n",
    "    \"global_map\": {\n",
    "        \"No internet service\": \"No\",\n",
    "        \"No phone service\": \"No\",\n",
    "        \"n/a\": \"No\",\n",
    "        \"none\": \"No\"\n",
    "    },\n",
    "    \"null_values\": [\"\", \"na\", \"n/a\", \"-\"],\n",
    "    \"cast_to_category\": False\n",
    "}\n",
    "```\n",
    "\n",
    "Exemplo de mapa espec√≠fico por coluna:\n",
    "```python\n",
    "\"per_column_map\": {\n",
    "    \"InternetService\": {\"Dsl\": \"DSL\", \"Fiber Optic\": \"Fiber Optic\"}\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula realiza uma **padroniza√ß√£o inteligente e audit√°vel** das colunas categ√≥ricas ‚Äî aplicando limpeza, substitui√ß√µes e normaliza√ß√£o de forma sistem√°tica.  \n",
    "> O processo √© controlado via configura√ß√£o (`CAT_NORM_CFG`), gera um relat√≥rio autom√°tico e mant√©m registro completo no log e no `manifest.json`, garantindo **clareza, rastreabilidade e consist√™ncia** no tratamento dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99b83f96-33a7-4589-970e-9406d75eaaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,583 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,595 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-04 05:00:02,599 | INFO | [manifest] step='save_report_df' registrado.\n",
      "üìë Relat√≥rio de padroniza√ß√£o (top 20 por mudan√ßas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contract</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>5517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Churn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  changed\n",
       "0           Contract     7043\n",
       "1      PaymentMethod     7043\n",
       "2    InternetService     5517\n",
       "3     OnlineSecurity     1526\n",
       "4       OnlineBackup     1526\n",
       "5   DeviceProtection     1526\n",
       "6        TechSupport     1526\n",
       "7        StreamingTV     1526\n",
       "8    StreamingMovies     1526\n",
       "9      MultipleLines      682\n",
       "10            gender        0\n",
       "11           Partner        0\n",
       "12        Dependents        0\n",
       "13      PhoneService        0\n",
       "14  PaperlessBilling        0\n",
       "15             Churn        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Padroniza√ß√£o Categ√≥rica conclu√≠da (fun√ß√£o avan√ßada)\n",
      "‚Üí Shape: (7043, 21) ‚Üí (7043, 21) (Œîlinhas=+0, Œîcolunas=+0)\n",
      "‚Üí Mem√≥ria: 6.51 MB ‚Üí 6.51 MB (Œî=+0.00 MB)\n",
      "‚Üí Relat√≥rio salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\cat_normalization.csv\n"
     ]
    }
   ],
   "source": [
    "# Config gen√©rica de normaliza√ß√£o (ajuste √† vontade)\n",
    "CAT_NORM_CFG = {\n",
    "    \"enabled\": True,\n",
    "    \"exclude\": [\"customerID\"],          # nunca normalizar IDs\n",
    "    \"case\": \"title\",                    # \"lower\" | \"upper\" | \"title\"\n",
    "    \"strip_accents\": True,\n",
    "    \"collapse_ws\": True,\n",
    "    \"trim\": True,\n",
    "    \"global_map\": {\n",
    "        \"No internet service\": \"No\",\n",
    "        \"No phone service\": \"No\",\n",
    "        \"n/a\": \"No\",\n",
    "        \"none\": \"No\"\n",
    "    },\n",
    "    \"null_values\": [\"\", \"na\", \"n/a\", \"-\"],\n",
    "    \"cast_to_category\": False,\n",
    "    # \"per_column_map\": {\"PaperlessBilling\": {\"sim\": \"Yes\", \"nao\": \"No\"}}\n",
    "}\n",
    "\n",
    "# Guarda m√©tricas antes/depois\n",
    "_before_shape = df.shape\n",
    "_before_mem   = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "\n",
    "# Caminho de relat√≥rio\n",
    "cat_report_path = paths.reports_dir / \"cat_normalization.csv\"\n",
    "\n",
    "# Tentativa 1: usar a fun√ß√£o avan√ßada (com cfg e relat√≥rio)\n",
    "_used_fallback = False\n",
    "try:\n",
    "    df_norm, cat_norm_report = ud.normalize_categories(\n",
    "        df,\n",
    "        cfg=CAT_NORM_CFG,\n",
    "        report_path=cat_report_path  # aten√ß√£o: √© um caminho completo; essa fun√ß√£o j√° lida com Path\n",
    "    )\n",
    "except TypeError:\n",
    "    # Tentativa 2: fallback para vers√£o simples do utils (sem cfg, sem report interno)\n",
    "    _used_fallback = True\n",
    "\n",
    "    # Limita √†s colunas de texto e aplica \"exclude\" da config\n",
    "    text_cols = [c for c in df.columns if df[c].dtype == \"object\" or pd.api.types.is_string_dtype(df[c])]\n",
    "    target_cols = [c for c in text_cols if c not in set(CAT_NORM_CFG.get(\"exclude\", []))]\n",
    "\n",
    "    df_before = df.copy()\n",
    "\n",
    "    # Chamada da vers√£o simples\n",
    "    df_norm = ud.normalize_categories(\n",
    "        df,\n",
    "        cols=target_cols,\n",
    "        case=CAT_NORM_CFG.get(\"case\", \"lower\"),\n",
    "        trim=CAT_NORM_CFG.get(\"trim\", True),\n",
    "        strip_accents=CAT_NORM_CFG.get(\"strip_accents\", True),\n",
    "    )\n",
    "\n",
    "    # Se a fun√ß√£o simples retornar s√≥ o df, mantenha:\n",
    "    if isinstance(df_norm, tuple):\n",
    "        # alguma variante pode retornar (df, report); normaliza para df apenas\n",
    "        df_norm = df_norm[0]\n",
    "\n",
    "    # Constr√≥i um relat√≥rio equivalente (diferen√ßas por coluna)\n",
    "    changes = []\n",
    "    for c in target_cols:\n",
    "        changed = (df_before[c].astype(str) != df_norm[c].astype(str)).sum()\n",
    "        if changed > 0:\n",
    "            changes.append({\"column\": c, \"changed\": int(changed)})\n",
    "\n",
    "    cat_norm_report = pd.DataFrame(changes).sort_values(\"changed\", ascending=False).reset_index(drop=True)\n",
    "    cat_report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cat_norm_report.to_csv(cat_report_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Atualiza o df do pipeline\n",
    "df = df_norm\n",
    "\n",
    "# M√©tricas p√≥s\n",
    "_after_mem   = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "_delta_rows  = df.shape[0] - _before_shape[0]\n",
    "_delta_cols  = df.shape[1] - _before_shape[1]\n",
    "_delta_mem   = _after_mem - _before_mem\n",
    "\n",
    "# Exibi√ß√£o do relat√≥rio\n",
    "if isinstance(cat_norm_report, pd.DataFrame) and not cat_norm_report.empty:\n",
    "    print(\"üìë Relat√≥rio de padroniza√ß√£o (top 20 por mudan√ßas):\")\n",
    "    display(cat_norm_report.head(20))\n",
    "else:\n",
    "    print(\"‚úÖ Nenhuma mudan√ßa significativa detectada nas colunas categ√≥ricas.\")\n",
    "\n",
    "# Mensagem consolidada\n",
    "print(\n",
    "    f\"\\n‚úÖ Padroniza√ß√£o Categ√≥rica conclu√≠da \"\n",
    "    f\"{'(fallback simples)' if _used_fallback else '(fun√ß√£o avan√ßada)'}\\n\"\n",
    "    f\"‚Üí Shape: {_before_shape} ‚Üí {df.shape} (Œîlinhas={_delta_rows:+}, Œîcolunas={_delta_cols:+})\\n\"\n",
    "    f\"‚Üí Mem√≥ria: {_before_mem:.2f} MB ‚Üí {_after_mem:.2f} MB (Œî={_delta_mem:+.2f} MB)\\n\"\n",
    "    f\"‚Üí Relat√≥rio salvo em: {cat_report_path}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89dd8b-b72c-47c0-b6a7-35a774c94a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8569d5cd",
   "metadata": {},
   "source": [
    "## ü©π Tratamento de Valores Faltantes\n",
    "\n",
    "Nesta etapa s√£o tratadas as **aus√™ncias de dados** (valores nulos ou `NaN`) para garantir que o DataFrame siga consistente para as pr√≥ximas fases do pipeline.  \n",
    "O objetivo √© **preencher ou sinalizar valores faltantes** de forma controlada, preservando a integridade estat√≠stica das colunas e registrando quais linhas foram modificadas.\n",
    "\n",
    "### üìã O que √© feito aqui\n",
    "\n",
    "1. **Gera√ß√£o de relat√≥rio inicial**\n",
    "   - Exibe um diagn√≥stico das colunas com valores ausentes, mostrando a propor√ß√£o (`missing_rate`) e o total (`missing_count`) de registros nulos.\n",
    "   - Essa visualiza√ß√£o ajuda a decidir se o tratamento ser√° simples ou se exigir√° t√©cnicas espec√≠ficas.\n",
    "\n",
    "2. **Aplica√ß√£o da estrat√©gia de imputa√ß√£o**\n",
    "   - O comportamento √© controlado pela chave `missing_strategy` do arquivo de configura√ß√£o:\n",
    "     - `\"simple\"` ‚Üí aplica a fun√ß√£o `simple_impute_with_flags()`\n",
    "     - `\"advanced\"` ‚Üí reservado para m√©todos personalizados (ex.: KNN, regress√£o, interpola√ß√£o)\n",
    "   - A estrat√©gia **simples** executa:\n",
    "     - Substitui√ß√£o de valores nulos **num√©ricos** pela **mediana** da coluna.  \n",
    "     - Substitui√ß√£o de valores nulos **categ√≥ricos** pela **moda** (valor mais frequente).  \n",
    "   - Durante a imputa√ß√£o, s√£o criadas **colunas de flag** no formato `was_imputed_<coluna>`, indicando quais linhas foram alteradas.\n",
    "\n",
    "3. **Relat√≥rio final de verifica√ß√£o**\n",
    "   - Ap√≥s o preenchimento, √© exibido novamente o relat√≥rio de faltantes para confirmar se todas as lacunas foram resolvidas.\n",
    "   - Caso ainda existam colunas cr√≠ticas, o notebook pode ser ajustado para aplicar m√©todos mais avan√ßados.\n",
    "\n",
    "### Exemplo de flag gerada:\n",
    "| customerID | TotalCharges | was_imputed_TotalCharges |\n",
    "|-------------|--------------|--------------------------|\n",
    "| 7590-VHVEG  | 29.85        | False                   |\n",
    "| 9237-HQITU  | 1840.75      | True                    |\n",
    "\n",
    "Linhas com `True` indicam que o valor original estava ausente e foi imputado automaticamente.\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula identifica e corrige valores faltantes, aplicando regras de imputa√ß√£o simples e registrando onde cada substitui√ß√£o ocorreu.  \n",
    "> Isso garante **transpar√™ncia, rastreabilidade e controle de qualidade**, permitindo filtrar posteriormente apenas os dados considerados consistentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "04728790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,650 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,653 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,665 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-04 05:00:02,669 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\before.csv (21 linhas)\n",
      "2025-11-04 05:00:02,671 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\before.csv (21 linhas)\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,705 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,708 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,720 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-04 05:00:02,724 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\after.csv (42 linhas)\n",
      "2025-11-04 05:00:02,725 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\after.csv (42 linhas)\n",
      "\n",
      "‚úÖ Tratamento de faltantes conclu√≠do!\n",
      "‚Üí Estrat√©gia final: simple\n",
      "‚Üí Colunas imputadas (amostra): ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'customerID', 'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines']\n",
      "\n",
      "Relat√≥rio de faltantes (antes):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>11</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthlyCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tenure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SeniorCitizen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  missing_count  missing_pct\n",
       "0       TotalCharges             11         0.16\n",
       "1         customerID              0         0.00\n",
       "2   DeviceProtection              0         0.00\n",
       "3     MonthlyCharges              0         0.00\n",
       "4      PaymentMethod              0         0.00\n",
       "5   PaperlessBilling              0         0.00\n",
       "6           Contract              0         0.00\n",
       "7    StreamingMovies              0         0.00\n",
       "8        StreamingTV              0         0.00\n",
       "9        TechSupport              0         0.00\n",
       "10      OnlineBackup              0         0.00\n",
       "11            gender              0         0.00\n",
       "12    OnlineSecurity              0         0.00\n",
       "13   InternetService              0         0.00\n",
       "14     MultipleLines              0         0.00\n",
       "15      PhoneService              0         0.00\n",
       "16            tenure              0         0.00\n",
       "17        Dependents              0         0.00\n",
       "18           Partner              0         0.00\n",
       "19     SeniorCitizen              0         0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relat√≥rio de faltantes (depois):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InternetService_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MonthlyCharges_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TotalCharges_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customerID_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gender_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Partner_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dependents_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PhoneService_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultipleLines_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineSecurity_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineBackup_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DeviceProtection_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TechSupport_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>StreamingTV_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>StreamingMovies_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Contract_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PaperlessBilling_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PaymentMethod_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          column  missing_count  missing_pct\n",
       "0                     customerID              0          0.0\n",
       "1    InternetService_was_missing              0          0.0\n",
       "2     MonthlyCharges_was_missing              0          0.0\n",
       "3       TotalCharges_was_missing              0          0.0\n",
       "4         customerID_was_missing              0          0.0\n",
       "5             gender_was_missing              0          0.0\n",
       "6            Partner_was_missing              0          0.0\n",
       "7         Dependents_was_missing              0          0.0\n",
       "8       PhoneService_was_missing              0          0.0\n",
       "9      MultipleLines_was_missing              0          0.0\n",
       "10    OnlineSecurity_was_missing              0          0.0\n",
       "11                        gender              0          0.0\n",
       "12      OnlineBackup_was_missing              0          0.0\n",
       "13  DeviceProtection_was_missing              0          0.0\n",
       "14       TechSupport_was_missing              0          0.0\n",
       "15       StreamingTV_was_missing              0          0.0\n",
       "16   StreamingMovies_was_missing              0          0.0\n",
       "17          Contract_was_missing              0          0.0\n",
       "18  PaperlessBilling_was_missing              0          0.0\n",
       "19     PaymentMethod_was_missing              0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === N1 ¬∑ Tratamento de Valores Faltantes (compacto) =========================\n",
    "import importlib, utils.utils_data as ud\n",
    "importlib.reload(ud)\n",
    "\n",
    "# Garante df como DataFrame caso alguma etapa tenha retornado tupla\n",
    "df = ud.coerce_df(df)\n",
    "\n",
    "res = ud.handle_missing_step(\n",
    "    df,\n",
    "    config=config,                     # usa config[\"missing\"] ou chaves antigas\n",
    "    save_reports=True,                 # salva before/after em reports/missing/\n",
    "    prefer=\"auto\"                      # \"auto\" tenta strategy do config e faz fallback p/ simple\n",
    ")\n",
    "\n",
    "df = res[\"df\"]\n",
    "\n",
    "print(\"\\n‚úÖ Tratamento de faltantes conclu√≠do!\")\n",
    "print(f\"‚Üí Estrat√©gia final: {res['strategy']}\")\n",
    "print(f\"‚Üí Colunas imputadas (amostra): {res.get('imputed_cols', [])[:10] or '‚Äî'}\")\n",
    "\n",
    "from IPython.display import display\n",
    "print(\"\\nRelat√≥rio de faltantes (antes):\")\n",
    "display(res[\"before\"].head(20))\n",
    "\n",
    "print(\"\\nRelat√≥rio de faltantes (depois):\")\n",
    "display(res[\"after\"].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716dbdd1-2116-4c24-8c7b-ea23020a52e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc838d6",
   "metadata": {},
   "source": [
    "## üö© Detec√ß√£o de Outliers\n",
    "\n",
    "Esta etapa identifica **valores at√≠picos** nas colunas num√©ricas, adicionando colunas de flag (`*_is_outlier`) que indicam quais registros se desviam do padr√£o estat√≠stico esperado.  \n",
    "Essas colunas servem para **inspe√ß√£o e auditoria**, sem alterar ou remover dados ‚Äî a decis√£o de tratamento posterior (ajuste, exclus√£o ou manuten√ß√£o) √© **de neg√≥cio**.\n",
    "\n",
    "### ‚öôÔ∏è Como funciona\n",
    "\n",
    "1. **Verifica a configura√ß√£o**\n",
    "   - A execu√ß√£o depende da flag `detect_outliers` no arquivo `config/defaults.json`.  \n",
    "     Se estiver definida como `true`, a detec√ß√£o √© realizada.\n",
    "\n",
    "2. **Seleciona o m√©todo estat√≠stico**\n",
    "   - `\"iqr\"` ‚Üí usa o **Intervalo Interquartil (Interquartile Range)**:\n",
    "     - Calcula Q1 (25¬∫ percentil) e Q3 (75¬∫ percentil)\n",
    "     - Define limites:  \n",
    "       Inferior = Q1 ‚àí 1.5 √ó IQR  \n",
    "       Superior = Q3 + 1.5 √ó IQR\n",
    "     - Valores fora desse intervalo s√£o marcados como outliers.\n",
    "   - `\"zscore\"` ‚Üí usa o **desvio-padr√£o (Z-Score)**:\n",
    "     - Calcula a m√©dia (Œº) e o desvio-padr√£o (œÉ)\n",
    "     - Para cada valor, obt√©m `z = (x ‚àí Œº) / œÉ`\n",
    "     - Valores com |z| > 3 s√£o considerados outliers.\n",
    "\n",
    "3. **Cria√ß√£o de colunas de flag**\n",
    "   - Para cada vari√°vel num√©rica analisada, √© criada uma nova coluna:\n",
    "     ```\n",
    "     <coluna>_is_outlier\n",
    "     ```\n",
    "   - O valor ser√°:\n",
    "     - `True` ‚Üí registro identificado como outlier  \n",
    "     - `False` ‚Üí registro dentro do intervalo esperado\n",
    "\n",
    "4. **Registro no log**\n",
    "   - Ao final, o sistema registra no log quantas colunas de flag foram criadas:\n",
    "     ```\n",
    "     Outlier flags created: 4\n",
    "     ```\n",
    "     Significa que 4 colunas num√©ricas foram analisadas e receberam suas respectivas flags.\n",
    "\n",
    "### Exemplo de resultado\n",
    "\n",
    "| tenure | MonthlyCharges | TotalCharges | tenure_is_outlier | MonthlyCharges_is_outlier | TotalCharges_is_outlier |\n",
    "|--------|----------------|--------------|-------------------|----------------------------|--------------------------|\n",
    "| 5      | 35.50          | 190.00       | False             | False                      | False                    |\n",
    "| 72     | 120.00         | 9999.99      | False             | **True**                   | **True**                 |\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula adiciona colunas de marca√ß√£o para detectar valores at√≠picos de acordo com o m√©todo configurado.  \n",
    "> Os dados originais s√£o preservados, permitindo que a an√°lise posterior defina se esses registros devem ser **mantidos, ajustados ou removidos**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1338f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,909 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,925 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,928 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:02,940 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-04 05:00:02,946 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\outliers\\summary.csv (3 linhas)\n",
      "2025-11-04 05:00:02,949 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\outliers\\summary.csv (3 linhas)\n",
      "[INFO] [apply_outlier_flags] flags criadas: 3 | m√©todo=iqr\n",
      "2025-11-04 05:00:02,950 | INFO | [apply_outlier_flags] flags criadas: 3 | m√©todo=iqr\n",
      "3 flags criadas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tenure_is_outlier            0\n",
       "MonthlyCharges_is_outlier    0\n",
       "TotalCharges_is_outlier      0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(ud)\n",
    "\n",
    "cfg = ud.load_config()  # ou um dict manual\n",
    "\n",
    "df2, out_info = ud.apply_outlier_flags(df, config=cfg)\n",
    "\n",
    "print(out_info[\"created_flags\"], \"flags criadas\")\n",
    "display(pd.Series(out_info[\"counts\"]).sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62fdb26-0d83-4248-978f-73609c4c9cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9e0c7d5-5fc8-4a90-b531-0cb7885e88a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure_is_outlier            0\n",
       "MonthlyCharges_is_outlier    0\n",
       "TotalCharges_is_outlier      0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2.filter(like=\"_is_outlier\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b431b",
   "metadata": {},
   "source": [
    "## üß¨ Duplicidades\n",
    "\n",
    "Remove **linhas duplicadas** do DataFrame para evitar contagens infladas, vieses e ru√≠do em m√©tricas.\n",
    "\n",
    "### üìã O que acontece aqui\n",
    "- A duplicidade √© verificada **linha a linha**, considerando todas as colunas por padr√£o.  \n",
    "- A primeira ocorr√™ncia √© mantida e as demais s√£o removidas.\n",
    "\n",
    "### üîß Op√ß√µes (definidas no `config`)\n",
    "- `deduplicate.subset`: lista de colunas que definem a chave de deduplica√ß√£o.  \n",
    "  *Ex.:* `[\"customerID\"]` mant√©m apenas um registro por cliente.  \n",
    "- `deduplicate.keep`: pol√≠tica de reten√ß√£o ‚Äî `\"first\"`, `\"last\"` ou `false` (remove todas as repeti√ß√µes).\n",
    "\n",
    "### üß† Boas pr√°ticas\n",
    "- Utilize `subset` quando a duplicidade for **conceitual** (ex.: mesma pessoa/pedido), n√£o necessariamente toda a linha id√™ntica.\n",
    "- Em datasets extensos, a deduplica√ß√£o deve ser feita **ap√≥s** o tratamento de nulos e padroniza√ß√£o de texto, para evitar falsos positivos.\n",
    "\n",
    "> üí° **Resumo:** esta etapa garante um dataset **sem registros repetidos** segundo o crit√©rio configurado, mantendo a consist√™ncia das an√°lises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f8aee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [deduplicate_rows] Removidas 0 duplicadas (7043 ‚Üí 7043) | subset=ALL | keep=first\n",
      "2025-11-04 05:00:03,361 | INFO | [deduplicate_rows] Removidas 0 duplicadas (7043 ‚Üí 7043) | subset=ALL | keep=first\n"
     ]
    }
   ],
   "source": [
    "if cfg.get(\"deduplicate\"):\n",
    "    df = ud.deduplicate_rows(df, config=cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dc0ea",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Engenharia de Atributos\n",
    "\n",
    "Cria√ß√£o de novas colunas que capturem **rela√ß√µes, propor√ß√µes, categorias ou padr√µes** relevantes ao neg√≥cio.  \n",
    "Essa etapa √© inteiramente manual e depende do contexto do dataset.\n",
    "\n",
    "### üí° Exemplos:\n",
    "- **Raz√µes e propor√ß√µes:** `TotalCharges / tenure` ‚Üí gasto m√©dio mensal.  \n",
    "- **Flags categ√≥ricas:** `Contract == 'Month-to-month'` ‚Üí 1 se contrato mensal.  \n",
    "- **Contagens de servi√ßos:** soma de colunas bin√°rias (Yes/No).  \n",
    "\n",
    "Essas novas features tornam as an√°lises mais ricas e **melhoram a performance de modelos preditivos**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è O que o bloco de c√≥digo faz\n",
    "\n",
    "- Verifica se `feature_engineering` est√° **habilitado no config**.  \n",
    "- Aplica regras **autom√°ticas seguras** (ex.: log1p em colunas com alta assimetria, raz√£o de `TotalCharges / tenure`, flag `is_long_tenure_24m`, etc.).  \n",
    "- Permite **regras personalizadas** via `config`, como:\n",
    "  - `ratios`: lista de pares `[numerador, denominador, nome_da_nova_coluna]`\n",
    "  - `log1p_cols`: colunas nas quais aplicar transforma√ß√£o logar√≠tmica\n",
    "  - `binaries`: limiares para gerar flags booleanas\n",
    "  - `date_parts`: colunas de data das quais extrair partes (ano, m√™s, semana...)\n",
    "\n",
    "Quando nenhuma regra √© aplic√°vel, o notebook retorna:\n",
    "\n",
    "```\n",
    "‚ÑπÔ∏è Nenhuma engenharia de atributos aplicada.\n",
    "   - Verifique config['feature_engineering'].\n",
    "   - Exemplos de regras: log1p_cols, ratios, binaries, date_parts.\n",
    "   - Habilite enable_default_rules para heur√≠sticas autom√°ticas.\n",
    "```\n",
    "\n",
    "### üß† Boas pr√°ticas\n",
    "- Use nomes **claros e descritivos** para novas features (`avg_charge_per_month`, `is_tenure_ge_12m`, etc.).  \n",
    "- Evite criar colunas redundantes ou altamente correlacionadas.  \n",
    "- Sempre documente cada feature gerada ‚Äî especialmente se for usada em modelagem posterior.\n",
    "\n",
    "> üí° **Resumo:** esta etapa adiciona intelig√™ncia ao dataset, criando vari√°veis derivadas que capturam padr√µes impl√≠citos e aumentam o poder explicativo dos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4296c3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-04 05:00:07,374 | INFO | [feature_engineering] Features criadas: 6 -> ['SeniorCitizen_log1p', 'TotalCharges_was_missing_log1p', 'avg_charge_per_month', 'charge_gap', 'charge_gap_log1p', 'is_long_tenure_24m']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen_log1p</th>\n",
       "      <th>TotalCharges_was_missing_log1p</th>\n",
       "      <th>avg_charge_per_month</th>\n",
       "      <th>charge_gap</th>\n",
       "      <th>charge_gap_log1p</th>\n",
       "      <th>is_long_tenure_24m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.850000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.573529</td>\n",
       "      <td>-46.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.075000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.905556</td>\n",
       "      <td>-62.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.825000</td>\n",
       "      <td>10.25</td>\n",
       "      <td>2.420368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.562500</td>\n",
       "      <td>23.30</td>\n",
       "      <td>3.190476</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.609091</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.190000</td>\n",
       "      <td>4.40</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.787500</td>\n",
       "      <td>111.65</td>\n",
       "      <td>4.724286</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.257258</td>\n",
       "      <td>6.65</td>\n",
       "      <td>2.034706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen_log1p  TotalCharges_was_missing_log1p  avg_charge_per_month  \\\n",
       "0                  0.0                             0.0             29.850000   \n",
       "1                  0.0                             0.0             55.573529   \n",
       "2                  0.0                             0.0             54.075000   \n",
       "3                  0.0                             0.0             40.905556   \n",
       "4                  0.0                             0.0             75.825000   \n",
       "5                  0.0                             0.0            102.562500   \n",
       "6                  0.0                             0.0             88.609091   \n",
       "7                  0.0                             0.0             30.190000   \n",
       "8                  0.0                             0.0            108.787500   \n",
       "9                  0.0                             0.0             56.257258   \n",
       "\n",
       "   charge_gap  charge_gap_log1p  is_long_tenure_24m  \n",
       "0        0.00          0.000000               False  \n",
       "1      -46.80          0.000000                True  \n",
       "2        0.45          0.371564               False  \n",
       "3      -62.75          0.000000                True  \n",
       "4       10.25          2.420368               False  \n",
       "5       23.30          3.190476               False  \n",
       "6      -10.80          0.000000               False  \n",
       "7        4.40          1.686399               False  \n",
       "8      111.65          4.724286                True  \n",
       "9        6.65          2.034706                True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Engenharia de Atributos -------------------------------------------------\n",
    "# Regras opcionais no config:\n",
    "# config.get(\"feature_engineering\") pode ser:\n",
    "#   - True/False\n",
    "#   - dict com op√ß√µes:\n",
    "#       {\n",
    "#         \"enable_default_rules\": True,\n",
    "#         \"log1p_cols\": [\"MonthlyCharges\"],\n",
    "#         \"ratios\": [[\"TotalCharges\",\"tenure\",\"avg_charge_per_month\"]],  # num/den->nome\n",
    "#         \"binaries\": [[\"tenure\", 24, \"is_long_tenure\"]],                # col, limiar, nome\n",
    "#         \"date_parts\": [\"order_date\"]                                   # extrai ano/mes/dia/semana\n",
    "#       }\n",
    "\n",
    "\n",
    "fe_cfg = config.get(\"feature_engineering\", False)\n",
    "if not fe_cfg:\n",
    "    print(\"‚öôÔ∏è FE desabilitada em config['feature_engineering'].\")\n",
    "else:\n",
    "    created = []\n",
    "\n",
    "    # helper p/ log\n",
    "    def _log(msg):\n",
    "        try:\n",
    "            logger.info(msg)  # se voc√™ tiver logger configurado\n",
    "        except:\n",
    "            print(msg)\n",
    "\n",
    "    # Normaliza config em dict\n",
    "    if isinstance(fe_cfg, bool):\n",
    "        fe_cfg = {\"enable_default_rules\": True}\n",
    "\n",
    "    # -------------------- 1) Regras expl√≠citas do config --------------------\n",
    "    # (a) Raz√µes num√©ricas definidas pelo usu√°rio: [[num, den, nome], ...]\n",
    "    for rule in fe_cfg.get(\"ratios\", []) or []:\n",
    "        if len(rule) == 3:\n",
    "            num, den, out = rule\n",
    "            if {num, den}.issubset(df.columns):\n",
    "                denom = df[den].replace(0, np.nan)\n",
    "                df[out] = df[num] / denom\n",
    "                created.append(out)\n",
    "\n",
    "    # (b) Log1p em colunas positivas\n",
    "    for col in fe_cfg.get(\"log1p_cols\", []) or []:\n",
    "        if col in df.columns:\n",
    "            pos = df[col] > 0\n",
    "            if pos.any():\n",
    "                out = f\"{col}_log1p\"\n",
    "                df[out] = 0.0\n",
    "                df.loc[pos, out] = np.log1p(df.loc[pos, col].astype(float))\n",
    "                created.append(out)\n",
    "\n",
    "    # (c) Bin√°rios por limiar: [[col, threshold, out_name], ...]\n",
    "    for rule in fe_cfg.get(\"binaries\", []) or []:\n",
    "        if len(rule) == 3:\n",
    "            col, thr, out = rule\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    df[out] = (pd.to_numeric(df[col], errors=\"coerce\") >= float(thr))\n",
    "                    created.append(out)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    # (d) Partes de data (ano, m√™s, dia, semana ISO)\n",
    "    for col in fe_cfg.get(\"date_parts\", []) or []:\n",
    "        if col in df.columns and pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            for part, accessor in {\n",
    "                \"year\": \"year\", \"month\": \"month\", \"day\": \"day\", \"week\": \"isocalendar().week\"\n",
    "            }.items():\n",
    "                out = f\"{col}_{part}\"\n",
    "                try:\n",
    "                    if part == \"week\":\n",
    "                        df[out] = getattr(df[col].dt.isocalendar(), \"week\")\n",
    "                    else:\n",
    "                        df[out] = getattr(df[col].dt, part)\n",
    "                    created.append(out)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    # -------------------- 2) Regras padr√£o (heur√≠sticas seguras) ------------\n",
    "    if fe_cfg.get(\"enable_default_rules\", True):\n",
    "        # (a) Telco cl√°ssico: cobran√ßa m√©dia mensal estimada\n",
    "        if {\"TotalCharges\", \"tenure\"}.issubset(df.columns):\n",
    "            denom = pd.to_numeric(df[\"tenure\"], errors=\"coerce\").replace(0, np.nan)\n",
    "            out = \"avg_charge_per_month\"\n",
    "            df[out] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\") / denom\n",
    "            created.append(out)\n",
    "\n",
    "        # (b) Diferen√ßa entre o esperado (tenure*Monthly) e TotalCharges\n",
    "        if {\"MonthlyCharges\", \"tenure\", \"TotalCharges\"}.issubset(df.columns):\n",
    "            exp_total = (\n",
    "                pd.to_numeric(df[\"MonthlyCharges\"], errors=\"coerce\") *\n",
    "                pd.to_numeric(df[\"tenure\"], errors=\"coerce\")\n",
    "            )\n",
    "            out = \"charge_gap\"\n",
    "            df[out] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\") - exp_total\n",
    "            created.append(out)\n",
    "\n",
    "        # (c) Limiar simples de fidelidade\n",
    "        if \"tenure\" in df.columns:\n",
    "            out = \"is_long_tenure_24m\"\n",
    "            df[out] = (pd.to_numeric(df[\"tenure\"], errors=\"coerce\") >= 24)\n",
    "            created.append(out)\n",
    "\n",
    "        # (d) log1p autom√°tico em num√©ricas com valores > 0 e forte assimetria\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in num_cols:\n",
    "            s = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            if (s > 0).sum() > 0:\n",
    "                skew = s.skew(skipna=True)\n",
    "                if pd.notna(skew) and abs(skew) > 1.0:\n",
    "                    out = f\"{col}_log1p\"\n",
    "                    # evita recriar se j√° existe por config\n",
    "                    if out not in df.columns:\n",
    "                        df[out] = np.log1p(s.clip(lower=0))\n",
    "                        created.append(out)\n",
    "\n",
    "    # -------------------- 3) Relato do que foi feito -------------------------\n",
    "    if created:\n",
    "        created = sorted(set(created))\n",
    "        _log(f\"[feature_engineering] Features criadas: {len(created)} -> {created[:8]}{'...' if len(created)>8 else ''}\")\n",
    "        # Visual r√°pido (limita para n√£o poluir)\n",
    "        display(df[created].head(10))\n",
    "    else:\n",
    "        _log(\"[feature_engineering] Nenhuma feature criada (sem regras aplic√°veis para as colunas atuais).\")\n",
    "        print(\n",
    "            \"‚ÑπÔ∏è Nenhuma engenharia de atributos aplicada.\\n\"\n",
    "            \"   - Verifique `config['feature_engineering']`.\\n\"\n",
    "            \"   - Exemplos de regras: \"\n",
    "            \"`log1p_cols`, `ratios`, `binaries`, `date_parts`.\\n\"\n",
    "            \"   - Habilite `enable_default_rules` para heur√≠sticas autom√°ticas.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5ccf2-b2c4-4566-8d40-f6c8fce99d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e32a1c18",
   "metadata": {},
   "source": [
    "# üìÖ Tratamento de Datas\n",
    "\n",
    "Esta etapa detecta e converte colunas de datas de forma **autom√°tica e controlada**, criando **features temporais** √∫teis para an√°lises e modelos preditivos.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã O que acontece aqui\n",
    "\n",
    "### üîπ Identifica√ß√£o de colunas de data\n",
    "\n",
    "O sistema procura automaticamente colunas com nomes que contenham termos como  \n",
    "`date`, `data`, `dt_`, `_dt`, ou `_date`.\n",
    "\n",
    "Tamb√©m √© poss√≠vel **for√ßar colunas espec√≠ficas** definindo manualmente em:\n",
    "\n",
    "```python\n",
    "date_cfg[\"explicit_cols\"] = [\"StartDate\", \"EndDate\"]\n",
    "```\n",
    "\n",
    "### üîπ Convers√£o para datetime com auditoria\n",
    "\n",
    "Cada coluna candidata √© testada com diferentes formatos e tentativas de *parsing*.  \n",
    "O relat√≥rio **`parse_report`** mostra:\n",
    "\n",
    "| column      | parsed_ratio | converted |\n",
    "|--------------|--------------|------------|\n",
    "| order_date   | 1.00         | True       |\n",
    "| start_date   | 0.35         | False      |\n",
    "\n",
    "- **column:** nome da coluna testada  \n",
    "- **parsed_ratio:** porcentagem de valores convertidos com sucesso  \n",
    "- **converted:** indica se a coluna foi convertida (baseado no `min_ratio`)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Cria√ß√£o autom√°tica de features temporais\n",
    "\n",
    "Para cada coluna convertida em `datetime`, s√£o geradas vari√°veis derivadas como:\n",
    "\n",
    "`*_year`, `*_month`, `*_day`, `*_dayofweek`, `*_quarter`, `*_week`,  \n",
    "`*_is_month_start`, `*_is_month_end`\n",
    "\n",
    "O prefixo das novas colunas √© o **nome original da coluna de data** .\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Comportamento defensivo\n",
    "\n",
    "Caso nenhuma coluna seja detectada, a c√©lula n√£o gera erro ‚Äî apenas loga:\n",
    "\n",
    "`[dates] Nenhuma coluna de data detectada/convertida. Pule a cria√ß√£o de features.`\n",
    "\n",
    "\n",
    "Assim, o pipeline segue normalmente.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Configura√ß√£o (`date_cfg`)\n",
    "\n",
    "| Par√¢metro       | Descri√ß√£o                                                        | Exemplo               |\n",
    "|-----------------|------------------------------------------------------------------|------------------------|\n",
    "| `detect_regex`  | Padr√£o para localizar colunas com nomes de data                 | `\"date\"`              |\n",
    "| `explicit_cols` | Lista manual de colunas a converter                             | `[\"StartDate\"]`       |\n",
    "| `dayfirst`      | Define se o formato √© D/M/Y                                     | `True` para üáßüá∑        |\n",
    "| `utc`           | Define se a convers√£o deve ser em UTC                           | `False`               |\n",
    "| `formats`       | Lista de formatos espec√≠ficos                                   | `[\"%d/%m/%Y\"]`        |\n",
    "| `min_ratio`     | Fra√ß√£o m√≠nima de parsing bem-sucedido para aceitar a convers√£o  | `0.8`                 |\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula realiza o reconhecimento autom√°tico de colunas de data,\n",
    "converte-as para o formato datetime e gera vari√°veis derivadas como\n",
    "ano, m√™s, dia e semana.\n",
    "> Caso nenhuma coluna de data seja encontrada, o c√≥digo √© ignorado com seguran√ßa,\n",
    "garantindo a continuidade do pipeline sem erros.\n",
    "> Os par√¢metros em date_cfg permitem ajustar formato, localiza√ß√£o e toler√¢ncia\n",
    "de parsing conforme a estrutura de cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14c4c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:07,801 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:07,805 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:07,817 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-04 05:00:07,820 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\date_parse_report.csv (0 linhas)\n",
      "2025-11-04 05:00:07,822 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\date_parse_report.csv (0 linhas)\n",
      "[INFO] [dates/cfg] parsed_cols=[] (min_ratio=0.8)\n",
      "2025-11-04 05:00:07,823 | INFO | [dates/cfg] parsed_cols=[] (min_ratio=0.8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>non_null</th>\n",
       "      <th>parsed</th>\n",
       "      <th>ratio</th>\n",
       "      <th>method</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column, non_null, parsed, ratio, method, format]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-04 05:00:07,831 | INFO | [dates] Nenhuma coluna de data detectada/convertida. Pule a cria√ß√£o de features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_11372\\65037927.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n"
     ]
    }
   ],
   "source": [
    "# --- Tratamento de Datas -----------------------------------------------------\n",
    "# Usa cfg do arquivo defaults.json (se preferir, mantenha o dict local)\n",
    "date_cfg = dict(config.get(\"dates\", {})) or {\n",
    "    \"detect_regex\": r\"(date|data|dt_|_dt$|_date$|_at$|time|timestamp|created|updated)\",\n",
    "    \"explicit_cols\": [],   # ex.: [\"StartDate\",\"EndDate\"]\n",
    "    \"dayfirst\": False,     # True se D/M/Y (BR)\n",
    "    \"utc\": False,\n",
    "    \"formats\": [],         # ex.: [\"%d/%m/%Y\", \"%Y-%m-%d\"]\n",
    "    \"min_ratio\": 0.80,\n",
    "    \"report_path\": \"date_parse_report.csv\"\n",
    "}\n",
    "\n",
    "df, parse_report, parsed_cols = ud.parse_dates_with_report_cfg(df, date_cfg)\n",
    "display(parse_report)\n",
    "\n",
    "if not parsed_cols:\n",
    "    logger.info(\"[dates] Nenhuma coluna de data detectada/convertida. Pule a cria√ß√£o de features.\")\n",
    "    # Scanner r√°pido de suspeitas (em colunas object), √∫til para alimentar explicit_cols/formats\n",
    "    obj_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "    suspects = []\n",
    "    for c in obj_cols:\n",
    "        s = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=date_cfg.get(\"dayfirst\", False), utc=date_cfg.get(\"utc\", False))\n",
    "        ratio = float(s.notna().mean())\n",
    "        if ratio >= 0.20:  # ajuste conforme seu caso\n",
    "            suspects.append((c, round(ratio, 3)))\n",
    "    if suspects:\n",
    "        print(\"üîé Poss√≠veis colunas de data (taxa de parsing com heur√≠stica atual):\")\n",
    "        display(pd.DataFrame(suspects, columns=[\"column\",\"parse_ratio\"]).sort_values(\"parse_ratio\", ascending=False))\n",
    "        print(\"‚Üí Dica: mova as colunas acima para dates.explicit_cols e/ou informe dates.formats.\")\n",
    "else:\n",
    "    created = ud.expand_date_features_plus(\n",
    "        df, parsed_cols,\n",
    "        features=[\"year\",\"month\",\"day\",\"dayofweek\",\"quarter\",\"week\",\"is_month_start\",\"is_month_end\"],\n",
    "        prefix_mode=\"auto\"\n",
    "    )\n",
    "    logger.info(f\"[dates] features criadas: {len(created)}\")\n",
    "    display(df[created].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba5ef3-1c6b-41c3-9347-e6e7ec0812e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18f0ad24-b7dc-4e36-98f9-97f790b7aafa",
   "metadata": {},
   "source": [
    "# üóìÔ∏è Cria√ß√£o da Tabela Calend√°rio (`dim_date`)\n",
    "\n",
    "Esta etapa gera automaticamente uma **tabela calend√°rio completa** ‚Äî tamb√©m chamada de **dimens√£o de tempo** ‚Äî a partir de uma coluna de datas existente no dataset principal.  \n",
    "A tabela √© √∫til para **an√°lises temporais, dashboards e modelos de previs√£o** que utilizam per√≠odos como refer√™ncia (ano, m√™s, trimestre, etc).\n",
    "\n",
    "---\n",
    "\n",
    "## üìã O que acontece aqui\n",
    "\n",
    "### üîπ Sele√ß√£o da coluna de data\n",
    "\n",
    "Voc√™ define manualmente qual coluna ser√° usada como base:\n",
    "\n",
    "```python\n",
    "CAL_DATE_COL = \"order_date\"  # nome da coluna datetime escolhida\n",
    "CAL_FREQ = \"D\"               # frequ√™ncia: \"D\" (di√°rio), \"W\" (semanal), \"M\" (mensal)\n",
    "```\n",
    "\n",
    "A coluna deve estar no formato **datetime**.  \n",
    "Se n√£o estiver, o notebook exibir√° um aviso pedindo para executar antes a etapa de **Tratamento de Datas**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Gera√ß√£o da dimens√£o calend√°rio\n",
    "\n",
    "A fun√ß√£o `build_calendar_from()` constr√≥i uma tabela com todas as datas entre o **m√≠nimo** e o **m√°ximo** encontrados em `CAL_DATE_COL`.\n",
    "\n",
    "Para cada data, s√£o criadas colunas derivadas, como:\n",
    "\n",
    "| Coluna          | Descri√ß√£o                                |\n",
    "|------------------|-------------------------------------------|\n",
    "| `date`           | Data base (chave prim√°ria)               |\n",
    "| `year`           | Ano                                      |\n",
    "| `month`          | M√™s num√©rico                             |\n",
    "| `day`            | Dia do m√™s                               |\n",
    "| `quarter`        | Trimestre (1‚Äì4)                          |\n",
    "| `week`           | Semana do ano (ISO)                      |\n",
    "| `dow`            | Dia da semana (0 = segunda, 6 = domingo) |\n",
    "| `is_month_start` | Indica se a data √© o primeiro dia do m√™s |\n",
    "| `is_month_end`   | Indica se a data √© o √∫ltimo dia do m√™s   |\n",
    "| `month_name`     | Nome do m√™s                              |\n",
    "| `day_name`       | Nome do dia da semana                    |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Armazenamento e reuso\n",
    "\n",
    "A tabela √© salva automaticamente no diret√≥rio de artefatos do projeto (`reports/artifacts`), usando o utilit√°rio:\n",
    "\n",
    "```python\n",
    "CAL_OUT = ud.get_artifacts_dir(\"calendar\") / \"dim_date.csv\"\n",
    "ud.save_table(dim_date, CAL_OUT)\n",
    "```\n",
    "\n",
    "O formato √© determinado pela extens√£o do arquivo ‚Äî `.csv` ou `.parquet`.\n",
    "\n",
    "Al√©m disso, a tabela pode ser registrada no cat√°logo de DataFrames (`T`) para ser usada em outras partes do pipeline:\n",
    "\n",
    "```python\n",
    "T.add(\"dim_date\", dim_date)\n",
    "```\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula cria uma **dimens√£o de tempo completa** a partir da coluna de data escolhida.  \n",
    "> O processo √© **autom√°tico**, **reproduz√≠vel** e **independente do dataset principal**, permitindo:\n",
    "> - Agrega√ß√µes temporais por ano, m√™s, semana ou trimestre;  \n",
    "> - Jun√ß√µes consistentes com outras tabelas de fato;  \n",
    "> - Integra√ß√£o direta com dashboards (ex.: Power BI).  \n",
    "> \n",
    "> Tudo √© salvo e versionado dentro da estrutura padr√£o do projeto em `reports/artifacts/calendar/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb7f1368-d692-4703-a297-5298e186e576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Coluna 'order_date' n√£o encontrada no DataFrame. Ajuste CAL_DATE_COL para uma coluna v√°lida antes de gerar a tabela calend√°rio.\n",
      "2025-11-04 05:00:09,237 | WARNING | ‚ö†Ô∏è Coluna 'order_date' n√£o encontrada no DataFrame. Ajuste CAL_DATE_COL para uma coluna v√°lida antes de gerar a tabela calend√°rio.\n"
     ]
    }
   ],
   "source": [
    "# --- valida√ß√µes suaves ---\n",
    "if CAL_DATE_COL not in df.columns:\n",
    "    msg = f\"‚ö†Ô∏è Coluna '{CAL_DATE_COL}' n√£o encontrada no DataFrame. \" \\\n",
    "          f\"Ajuste CAL_DATE_COL para uma coluna v√°lida antes de gerar a tabela calend√°rio.\"\n",
    "    print(msg); logger.warning(msg)\n",
    "else:\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[CAL_DATE_COL]):\n",
    "        msg = f\"‚ö†Ô∏è Coluna '{CAL_DATE_COL}' existe, mas **n√£o est√° em formato datetime**. \" \\\n",
    "              \"Execute a etapa de Tratamento de Datas antes, ou converta manualmente.\"\n",
    "        print(msg); logger.warning(msg)\n",
    "    else:\n",
    "        # --- constru√ß√£o da dimens√£o calend√°rio ---\n",
    "        dim_date = ud.build_calendar_from(df, CAL_DATE_COL, freq=CAL_FREQ)\n",
    "\n",
    "        # --- vis√£o r√°pida ---\n",
    "        display(dim_date.head(12))\n",
    "        start_date = dim_date[\"date\"].min()\n",
    "        end_date   = dim_date[\"date\"].max()\n",
    "        print(f\"Per√≠odo: {start_date.date()} ‚Üí {end_date.date()}  | Linhas: {len(dim_date)}\")\n",
    "\n",
    "        # --- salvar respeitando a extens√£o (.csv ou .parquet pelo sufixo)\n",
    "        ud.save_table(dim_date, CAL_OUT)\n",
    "        logger.info(f\"[calendar] Tabela calend√°rio salva em: {CAL_OUT}\")\n",
    "\n",
    "        # --- opcional: registrar no cat√°logo de tabelas ---\n",
    "        try:\n",
    "            T.add(\"dim_date\", dim_date)\n",
    "            logger.info(\"[calendar] 'dim_date' registrada no cat√°logo T.\")\n",
    "        except NameError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf4856",
   "metadata": {},
   "source": [
    "# üìù Tratamento de Texto (opcional)\n",
    "\n",
    "Esta etapa extrai **m√©tricas num√©ricas e l√≥gicas a partir de colunas textuais**, transformando texto livre em informa√ß√µes quantitativas √∫teis para **an√°lise explorat√≥ria e modelagem**.  \n",
    "\n",
    "√â uma forma leve e controlada de **estruturar dados n√£o num√©ricos**, sem recorrer a t√©cnicas avan√ßadas de NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã O que acontece aqui\n",
    "\n",
    "### üîπ Identifica√ß√£o de colunas textuais\n",
    "\n",
    "O sistema busca automaticamente colunas com tipo `object` e ignora aquelas listadas na *blacklist*:\n",
    "\n",
    "```python\n",
    "text_cols = [c for c in df.columns if df[c].dtype == 'object' and c not in TEXT_CFG[\"blacklist\"]]\n",
    "```\n",
    "\n",
    "Essas colunas normalmente cont√™m informa√ß√µes como:  \n",
    "descri√ß√µes, coment√°rios, nomes, categorias textuais ou observa√ß√µes.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Limpeza e padroniza√ß√£o\n",
    "\n",
    "Antes de gerar as m√©tricas, os textos passam por uma limpeza leve:\n",
    "- Remo√ß√£o de **espa√ßos duplicados** e **trim** nas extremidades.  \n",
    "- Convers√£o para **min√∫sculas**, garantindo consist√™ncia em an√°lises de termos.\n",
    "\n",
    "Essas a√ß√µes s√£o controladas pelas chaves:\n",
    "```python\n",
    "\"lower\": True,\n",
    "\"strip_collapse_ws\": True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Cria√ß√£o autom√°tica de m√©tricas textuais\n",
    "\n",
    "Para cada coluna textual, s√£o geradas novas colunas num√©ricas:\n",
    "\n",
    "| Nova Coluna           | Descri√ß√£o | Exemplo (\"This is great!\") |\n",
    "|------------------------|------------|-----------------------------|\n",
    "| `<coluna>_len`         | N√∫mero total de caracteres no texto | 15 |\n",
    "| `<coluna>_word_count`  | N√∫mero de palavras separadas por espa√ßos | 3 |\n",
    "\n",
    "Essas novas colunas permitem an√°lises quantitativas sobre padr√µes de texto e s√£o especialmente √∫teis em relat√≥rios e modelos de ML que exigem vari√°veis num√©ricas.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Presen√ßa de termos-chave\n",
    "\n",
    "O sistema tamb√©m cria colunas booleanas (`True` / `False`) para identificar a **ocorr√™ncia de palavras espec√≠ficas** em cada coluna textual.  \n",
    "\n",
    "Exemplo:\n",
    "```python\n",
    "TEXT_CFG[\"keywords\"] = [\"error\", \"cancel\", \"premium\"]\n",
    "```\n",
    "\n",
    "Gera colunas como:\n",
    "- `<coluna>_has_error`  \n",
    "- `<coluna>_has_cancel`  \n",
    "- `<coluna>_has_premium`\n",
    "\n",
    "Essas vari√°veis s√£o √∫teis para an√°lises de sentimento, classifica√ß√£o de textos e detec√ß√£o de padr√µes em feedbacks de clientes.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Exporta√ß√£o de resumo\n",
    "\n",
    "Ao final, √© gerado um **resumo CSV** com as colunas de texto processadas e suas m√©tricas derivadas.  \n",
    "O arquivo √© salvo automaticamente em:\n",
    "\n",
    "```\n",
    "reports/artifacts/text_features/text_features_summary.csv\n",
    "```\n",
    "\n",
    "Esse relat√≥rio documenta as transforma√ß√µes aplicadas, garantindo **rastreabilidade e transpar√™ncia** dentro do pipeline de dados.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Configura√ß√£o (`TEXT_CFG`)\n",
    "\n",
    "| Par√¢metro              | Descri√ß√£o                                                       | Exemplo                              |\n",
    "|------------------------|------------------------------------------------------------------|--------------------------------------|\n",
    "| `lower`                | Converte o texto para min√∫sculas                                | `True`                               |\n",
    "| `strip_collapse_ws`    | Remove espa√ßos duplicados e limpa extremidades                  | `True`                               |\n",
    "| `keywords`             | Lista de termos a detectar no texto                             | `[\"error\", \"cancel\", \"premium\"]`     |\n",
    "| `blacklist`            | Colunas a ignorar durante o processamento                       | `[\"customerID\"]`                     |\n",
    "| `export_summary`       | Salva relat√≥rio com resumo das features geradas                 | `True`                               |\n",
    "\n",
    "---\n",
    "\n",
    "### Boas pr√°ticas\n",
    "\n",
    "- Aplique esta etapa apenas em colunas realmente textuais ‚Äî evite IDs ou c√≥digos.  \n",
    "- Personalize a lista de **palavras-chave** conforme o contexto do dataset.  \n",
    "- Caso o dataset n√£o possua colunas de texto, o processo ser√° ignorado com seguran√ßa.  \n",
    "- Utilize o relat√≥rio `text_features_summary.csv` para acompanhar colunas derivadas e auditorias.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula transforma campos de texto em **indicadores num√©ricos e l√≥gicos**, gerando m√©tricas b√°sicas (tamanho, n√∫mero de palavras e flags de palavras-chave).  \n",
    "> Tudo √© processado automaticamente com **configura√ß√£o leve e reprodut√≠vel**, integrando dados textuais ao pipeline de forma organizada e escal√°vel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae0f5bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:09,952 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\n",
      "2025-11-04 05:00:09,955 | INFO | [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\n",
      "[INFO] [text] resumo salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\\text_features_summary.csv (16 colunas)\n",
      "2025-11-04 05:00:10,369 | INFO | [text] resumo salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\\text_features_summary.csv (16 colunas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\\utils_data.py:1629: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_out[kw_flag] = s.str.contains(rf\"\\b{kw}\\b\", regex=True, na=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>non_null</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>avg_words</th>\n",
       "      <th>kw_error_count</th>\n",
       "      <th>kw_cancel_count</th>\n",
       "      <th>kw_premium_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Churn</td>\n",
       "      <td>7043</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contract</td>\n",
       "      <td>7043</td>\n",
       "      <td>11.30</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>7043</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>7043</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>7043</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  non_null  avg_len  avg_words  kw_error_count  \\\n",
       "0             Churn      7043     2.27       1.00               0   \n",
       "1          Contract      7043    11.30       1.45               0   \n",
       "2        Dependents      7043     2.30       1.00               0   \n",
       "3  DeviceProtection      7043     6.03       1.43               0   \n",
       "4   InternetService      7043     6.30       1.44               0   \n",
       "\n",
       "   kw_cancel_count  kw_premium_count  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEXT_CFG = {\n",
    "    \"lower\": True,\n",
    "    \"strip_collapse_ws\": True,\n",
    "    \"keywords\": [\"error\", \"cancel\", \"premium\"],\n",
    "    \"blacklist\": [\"customerID\"],\n",
    "    \"export_summary\": True,\n",
    "}\n",
    "\n",
    "if config.get(\"text_features\", True):\n",
    "    summary_path = ud.get_artifacts_dir(\"text_features\")\n",
    "    df, text_summary = ud.extract_text_features(\n",
    "        df,\n",
    "        lower=TEXT_CFG[\"lower\"],\n",
    "        strip_collapse_ws=TEXT_CFG[\"strip_collapse_ws\"],\n",
    "        keywords=TEXT_CFG[\"keywords\"],\n",
    "        blacklist=TEXT_CFG[\"blacklist\"],\n",
    "        export_summary=TEXT_CFG[\"export_summary\"],\n",
    "        summary_dir=summary_path\n",
    "    )\n",
    "    display(text_summary.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a35a9-05bd-45c1-8730-d8d73f62d83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfc2bc7f",
   "metadata": {},
   "source": [
    "# üî§ Codifica√ß√£o de Categ√≥ricas & üî¢ Escalonamento Num√©rico (opcionais)\n",
    "\n",
    "Esta etapa transforma vari√°veis **categ√≥ricas** em representa√ß√µes num√©ricas e **padroniza a escala** de vari√°veis **num√©ricas** quando necess√°rio.  \n",
    "√â √∫til para alimentar modelos de ML que **n√£o aceitam strings** (ex.: regress√µes, SVMs, redes neurais) e/ou **s√£o sens√≠veis √† escala** (KNN, SVM com kernel RBF, PCA, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Vis√£o Geral\n",
    "\n",
    "- **Codifica√ß√£o (Encoding)**\n",
    "  - **One-hot**: cria uma coluna por categoria (0/1). √â a op√ß√£o **mais segura** para baseline; evita ordenar categorias artificialmente.\n",
    "  - **Ordinal**: mapeia categorias para n√∫meros inteiros. Mais **compacto**, mas induz **ordem artificial**; use com cuidado quando **n√£o** h√° ordem natural.\n",
    "\n",
    "- **Escalonamento (Scaling)**\n",
    "  - **Standard**: `z = (x - m√©dia) / desvio`; centra em 0 com vari√¢ncia ‚âà 1. Bom para dados **aprox. gaussianos**.\n",
    "  - **MinMax**: escala para **[0, 1]**; √∫til quando limites m√≠nimos e m√°ximos s√£o relevantes (redes neurais, normaliza√ß√µes simples).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Configura√ß√£o usada no notebook\n",
    "\n",
    "As op√ß√µes abaixo s√£o lidas do `config` e repassadas para a fun√ß√£o utilit√°ria do template (`apply_encoding_and_scaling`, quando habilitada).\n",
    "\n",
    "```python\n",
    "ENCODE_CFG = {\n",
    "    \"enabled\":              config.get(\"encode_categoricals\", True),\n",
    "    \"type\":                 config.get(\"encoding_type\", \"onehot\"),  # \"onehot\" | \"ordinal\"\n",
    "    \"exclude_cols\":         [\"Churn\", \"customerID\"],                # N√ÉO codificar alvo/ids\n",
    "    \"high_card_threshold\":  50,                                     # ignora colunas com cardinalidade muito alta\n",
    "}\n",
    "\n",
    "SCALE_CFG = {\n",
    "    \"enabled\":              config.get(\"scale_numeric\", False),\n",
    "    \"method\":               config.get(\"scaler\", \"standard\"),       # \"standard\" | \"minmax\"\n",
    "    \"exclude_cols\":         [\"Churn\"],                              # N√ÉO escalar o alvo\n",
    "    \"only_continuous\":      True,                                   # evita escalar dummies e inteiros-discretos\n",
    "}\n",
    "\n",
    "df, encoding_meta, scaling_meta = apply_encoding_and_scaling(\n",
    "    df, encode_cfg=ENCODE_CFG, scale_cfg=SCALE_CFG\n",
    ")\n",
    "```\n",
    "\n",
    "> üí° **Dica:** deixe `scale_numeric = false` no in√≠cio do projeto (explora√ß√£o/entendimento).  \n",
    "> Ative a escala somente quando partir para **modelagem** e **valida√ß√£o**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© O que a fun√ß√£o faz (alto n√≠vel)\n",
    "\n",
    "1. **Seleciona colunas categ√≥ricas** (`object`/`category`) **excluindo** as listadas em `exclude_cols` e as com **cardinalidade > high_card_threshold** (prote√ß√£o contra explos√£o de dummies).\n",
    "2. **Codifica** conforme `type`:\n",
    "   - `onehot` ‚Üí usa `pd.get_dummies(..., dtype=float)` e concatena ao DataFrame (removendo as originais).\n",
    "   - `ordinal` ‚Üí usa `sklearn.preprocessing.OrdinalEncoder` (com `handle_unknown='use_encoded_value'` e `unknown_value=-1`).\n",
    "3. **Escala colunas num√©ricas** se `SCALE_CFG[\"enabled\"]`:\n",
    "   - seleciona **apenas** colunas num√©ricas **cont√≠nuas** quando `only_continuous=True` (tipicamente `float`/amplitude alta).\n",
    "   - aplica `StandardScaler` **ou** `MinMaxScaler` do scikit-learn.\n",
    "4. Retorna:\n",
    "   - `df` (atualizado),\n",
    "   - `encoding_meta` (categorias vistas, tipo de codifica√ß√£o, colunas exclu√≠das, descartes por cardinalidade),\n",
    "   - `scaling_meta` (tipo de escala, colunas escaladas, par√¢metros do scaler).\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Sa√≠das e Metadados\n",
    "\n",
    "**`encoding_meta`** inclui:\n",
    "- `encoding`: `\"onehot\"` **ou** `\"ordinal\"`  \n",
    "- `excluded`: lista de colunas ignoradas (ex.: `[\"Churn\",\"customerID\"]`)  \n",
    "- `high_card_excluded`: colunas **n√£o encodadas** por alta cardinalidade  \n",
    "- `categorical_columns`: colunas categ√≥ricas processadas  \n",
    "- (para ordinal) `categories_`: categorias aprendidas por coluna\n",
    "\n",
    "**`scaling_meta`** inclui:\n",
    "- `scaler`: `\"standard\"` **ou** `\"minmax\"`  \n",
    "- `scaled_columns`: lista das colunas escaladas  \n",
    "- `means_`/`scales_` (Standard) **ou** `min_`/`range_` (MinMax) ‚Äî √∫teis para **reprodu√ß√£o** no deploy\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Exemplo de comportamento esperado\n",
    "\n",
    "Dataset: `gender` (`Male`/`Female`), `InternetService` (DSL/Fiber/No), `MonthlyCharges` (float), `tenure` (int), `Churn` (alvo).\n",
    "\n",
    "Com `onehot` + `standard` e exclus√µes padr√£o, o resultado ser√°:\n",
    "- Novas colunas como `gender_Female`, `gender_Male`, `InternetService_DSL`, etc.\n",
    "- `MonthlyCharges` escalado (m√©dia‚âà0, desvio‚âà1); `tenure` **pode** ser ignorado do scaling se `only_continuous=True` e considerado discreto.\n",
    "\n",
    "---\n",
    "\n",
    "## üöß Armadilhas comuns e prote√ß√µes do template\n",
    "\n",
    "- **Explos√£o de dummies**: colunas com **muitas categorias** s√£o ignoradas (registradas em `high_card_excluded`).  \n",
    "- **Vazamento do alvo**: garanta que `exclude_cols` contenha a **target** (ex.: `\"Churn\"`).  \n",
    "- **IDs**: n√£o codificar/escalar IDs (`customerID`).  \n",
    "- **Mixed types**: colunas mal tipadas (n√∫mero como string) devem ser padronizadas antes (ver **Qualidade & Tipagem**).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Status de execu√ß√£o e logs\n",
    "\n",
    "Mensagens t√≠picas no log:\n",
    "\n",
    "```\n",
    "[encode] type=onehot | cols=['gender', 'InternetService'] | high_card_excluded=[]\n",
    "[scale] method=standard | scaled_cols=['MonthlyCharges']\n",
    "```\n",
    "\n",
    "Se o log mostrar `cols=[]`, significa que **n√£o h√° colunas categ√≥ricas** eleg√≠veis (ou foram exclu√≠das por configura√ß√£o/cardinalidade). Isso √© **normal** em alguns datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Boas pr√°ticas\n",
    "\n",
    "- Comece com **one-hot** e **sem escala** para uma baseline interpret√°vel.\n",
    "- Use **ordinal** s√≥ quando houver **ordem natural** nas categorias.\n",
    "- S√≥ escale **depois** do split treino/valida√ß√£o para evitar vazamento.\n",
    "- Salve `encoding_meta` e `scaling_meta` se for levar o modelo para produ√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula converte dados categ√≥ricos e num√©ricos em formatos ideais para modelagem, controlando exclus√µes, cardinalidade e escala ‚Äî garantindo **robustez**, **consist√™ncia** e **clareza** no tratamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7ebb07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:15,310 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\n",
      "2025-11-04 05:00:15,312 | INFO | [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\n",
      "[INFO] [text] resumo salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\\text_features_summary.csv (16 colunas)\n",
      "2025-11-04 05:00:15,767 | INFO | [text] resumo salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\text_features\\text_features_summary.csv (16 colunas)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>non_null</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>avg_words</th>\n",
       "      <th>kw_error_count</th>\n",
       "      <th>kw_cancel_count</th>\n",
       "      <th>kw_premium_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Churn</td>\n",
       "      <td>7043</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contract</td>\n",
       "      <td>7043</td>\n",
       "      <td>11.30</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>7043</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>7043</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>7043</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>7043</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>7043</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>7043</td>\n",
       "      <td>5.97</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>7043</td>\n",
       "      <td>2.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Partner</td>\n",
       "      <td>7043</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  non_null  avg_len  avg_words  kw_error_count  \\\n",
       "0             Churn      7043     2.27       1.00               0   \n",
       "1          Contract      7043    11.30       1.45               0   \n",
       "2        Dependents      7043     2.30       1.00               0   \n",
       "3  DeviceProtection      7043     6.03       1.43               0   \n",
       "4   InternetService      7043     6.30       1.44               0   \n",
       "5     MultipleLines      7043     3.78       1.19               0   \n",
       "6      OnlineBackup      7043     6.03       1.43               0   \n",
       "7    OnlineSecurity      7043     5.97       1.43               0   \n",
       "8  PaperlessBilling      7043     2.59       1.00               0   \n",
       "9           Partner      7043     2.48       1.00               0   \n",
       "\n",
       "   kw_cancel_count  kw_premium_count  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  \n",
       "5                0                 0  \n",
       "6                0                 0  \n",
       "7                0                 0  \n",
       "8                0                 0  \n",
       "9                0                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- üî§ Tratamento de Texto --------------------------------------------------\n",
    "TEXT_CFG = {\n",
    "    \"lower\": True,\n",
    "    \"strip_collapse_ws\": True,\n",
    "    \"keywords\": [\"error\", \"cancel\", \"premium\"],\n",
    "    \"blacklist\": [\"customerID\"],\n",
    "    \"export_summary\": True,\n",
    "}\n",
    "\n",
    "if config.get(\"text_features\", True):\n",
    "    summary_dir = ud.get_artifacts_dir(\"text_features\")\n",
    "\n",
    "    df, text_summary = ud.extract_text_features(\n",
    "        df,\n",
    "        lower=TEXT_CFG[\"lower\"],\n",
    "        strip_collapse_ws=TEXT_CFG[\"strip_collapse_ws\"],\n",
    "        keywords=TEXT_CFG[\"keywords\"],\n",
    "        blacklist=TEXT_CFG[\"blacklist\"],\n",
    "        export_summary=TEXT_CFG[\"export_summary\"],\n",
    "        summary_dir=summary_dir\n",
    "    )\n",
    "\n",
    "    display(text_summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94440a-3fe0-4802-97e9-70bd4d9a1da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf73cc16-7e72-4bf1-b6ec-14fd93f304e9",
   "metadata": {},
   "source": [
    "# üéØ Cria√ß√£o e Valida√ß√£o da Vari√°vel-Alvo (`target`)\n",
    "\n",
    "Esta etapa garante que o dataset contenha uma **vari√°vel-alvo bin√°ria** adequada para **modelos supervisionados de Machine Learning** ‚Äî como classifica√ß√£o de churn, fraude, aprova√ß√£o, entre outros.  \n",
    "\n",
    "O processo √© flex√≠vel e segue as instru√ß√µes definidas no arquivo `config/defaults.json`, permitindo que a cria√ß√£o do *target* seja **reproduz√≠vel e autom√°tica** em qualquer dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Configura√ß√£o do Target\n",
    "\n",
    "O comportamento √© controlado pela se√ß√£o `\"target\"` do arquivo de configura√ß√£o.  \n",
    "Exemplo t√≠pico (como no dataset *Telco Customer Churn*):\n",
    "\n",
    "```json\n",
    "\"target\": {\n",
    "  \"name\": \"Churn\",\n",
    "  \"source\": \"Churn\",\n",
    "  \"positive\": \"Yes\",\n",
    "  \"negative\": \"No\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Par√¢metros\n",
    "| Chave | Descri√ß√£o | Exemplo |\n",
    "|--------|------------|----------|\n",
    "| `name` | Nome final da coluna de destino | `\"Churn\"` |\n",
    "| `source` | Coluna de origem (se o nome for diferente) | `\"Churn\"` |\n",
    "| `positive` | Valor que representa a classe positiva | `\"Yes\"` |\n",
    "| `negative` | Valor que representa a classe negativa | `\"No\"` |\n",
    "\n",
    "> üí° **Dica:** se o dataset j√° tiver a coluna-alvo, a fun√ß√£o apenas validar√° e manter√° como est√° ‚Äî sem sobrescrever.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© O que o c√≥digo faz\n",
    "\n",
    "```python\n",
    "df, target_name, class_map, tgt_report = ud.ensure_target_from_config(df, config, verbose=True)\n",
    "display(tgt_report)\n",
    "globals()[\"class_map\"] = class_map\n",
    "```\n",
    "\n",
    "### Etapas internas:\n",
    "1. **Verifica se a coluna-alvo j√° existe**\n",
    "   - Se existir (`Churn`), exibe mensagem:  \n",
    "     ```\n",
    "     [target] Coluna 'Churn' j√° existe ‚Äî nenhuma a√ß√£o necess√°ria.\n",
    "     ```\n",
    "   - Caso contr√°rio, cria automaticamente a nova coluna de acordo com o `config`.\n",
    "\n",
    "2. **Aplica o mapeamento definido**\n",
    "   - Exemplo: `Yes ‚Üí 1`, `No ‚Üí 0`.\n",
    "\n",
    "3. **Retorna informa√ß√µes estruturadas**\n",
    "   - `target_name`: nome da coluna alvo  \n",
    "   - `class_map`: dicion√°rio de mapeamento de classes  \n",
    "   - `tgt_report`: pequeno relat√≥rio em formato DataFrame, exibindo status da opera√ß√£o\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Mini-relat√≥rio de valida√ß√£o\n",
    "\n",
    "Ap√≥s a execu√ß√£o, √© exibido algo como:\n",
    "\n",
    "| target | status     | source | positive | negative |\n",
    "|---------|-------------|---------|-----------|-----------|\n",
    "| Churn   | j√° existe  | Churn   | Yes       | No        |\n",
    "\n",
    "Esse relat√≥rio resume como o target foi identificado ou criado, garantindo rastreabilidade.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Verifica√ß√£o de consist√™ncia\n",
    "\n",
    "Ap√≥s criar (ou validar) a coluna-alvo, o notebook checa o conte√∫do e tipo:\n",
    "\n",
    "```python\n",
    "print(df[\"Churn\"].unique())\n",
    "print(df[\"Churn\"].value_counts())\n",
    "```\n",
    "\n",
    "Resultados esperados:\n",
    "\n",
    "| Caso | Exemplo de sa√≠da | Interpreta√ß√£o |\n",
    "|------|------------------|---------------|\n",
    "| Target bin√°rio correto | `[0, 1]` | ‚úÖ Pronto para ML |\n",
    "| Target textual | `['Yes', 'No']` | üîÑ Converter com `.map({'Yes':1,'No':0})` |\n",
    "| Target booleano | `[True, False]` | üîÑ Converter com `.astype(int)` |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Boas pr√°ticas\n",
    "\n",
    "- Defina claramente qual valor representa a **classe positiva** (ex.: `\"Yes\"`, `\"Exited\"`, `\"Churned\"`).  \n",
    "- Evite m√∫ltiplas colunas com o mesmo significado ‚Äî centralize em uma s√≥ (`target` ou `Churn`).  \n",
    "- Para modelos multiclasse, amplie o mapeamento conforme necess√°rio (ex.: `\"Gold\"`, `\"Silver\"`, `\"Bronze\"`).  \n",
    "- Sempre valide a distribui√ß√£o de classes com `value_counts()` antes da modelagem.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Integra√ß√£o com notebooks seguintes\n",
    "\n",
    "A vari√°vel `class_map` √© registrada globalmente para que o **Notebook N2** (modelagem) possa reutiliz√°-la:\n",
    "\n",
    "```python\n",
    "globals()[\"class_map\"] = class_map\n",
    "```\n",
    "\n",
    "Assim, o mapeamento de classes permanece dispon√≠vel para:\n",
    "- Convers√µes de r√≥tulos (`1 ‚Üí 'Yes'`, `0 ‚Üí 'No'`);\n",
    "- Exibi√ß√£o de resultados e m√©tricas em termos leg√≠veis.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula garante que o dataset contenha uma vari√°vel-alvo bin√°ria padronizada, compat√≠vel com os modelos de ML e definida de forma reprodut√≠vel via arquivo de configura√ß√£o.  \n",
    "> Se a coluna j√° existir, √© validada e mantida; se n√£o, √© criada conforme o mapeamento indicado no `config`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66c7b008-28cc-4e03-ad5d-38e4cf78ad51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target] Coluna 'Churn' j√° existe ‚Äî nenhuma a√ß√£o necess√°ria.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>status</th>\n",
       "      <th>source</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Churn</td>\n",
       "      <td>j√° existe</td>\n",
       "      <td>Churn</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target     status source positive negative\n",
       "0  Churn  j√° existe  Churn      Yes       No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando a consist√™ncia do tipo e dos valores:\n",
      "['no' 'yes']\n",
      "Churn\n",
      "no     5174\n",
      "yes    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cria o target a partir da config (ou defaults)\n",
    "df, target_name, class_map, tgt_report = ud.ensure_target_from_config(df, config, verbose=True)\n",
    "\n",
    "# Opcional: ver um mini-relat√≥rio\n",
    "display(tgt_report)\n",
    "\n",
    "# Garantir que o N2 enxergue o mapeamento, se voc√™ quiser usar class_map l√°:\n",
    "globals()[\"class_map\"] = class_map\n",
    "\n",
    "print('Verificando a consist√™ncia do tipo e dos valores:')\n",
    "print(df[\"Churn\"].unique())\n",
    "print(df[\"Churn\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5137d-ee47-4a16-99e1-c4bba70972e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5827a7",
   "metadata": {},
   "source": [
    "# üì¶ Exporta√ß√£o de Artefatos (N1 ‚Üí N2)\n",
    "\n",
    "Esta etapa consolida e exporta os **artefatos finais do notebook N1** ‚Äî garantindo que os dados tratados, os metadados e o manifesto de execu√ß√£o estejam dispon√≠veis para o **N2 (Modelagem)**.  \n",
    "\n",
    "√â o fechamento da fase de prepara√ß√£o dos dados, onde tudo que foi limpo, transformado e enriquecido √© salvo em **arquivos persistentes e reprodut√≠veis**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Vis√£o Geral do Processo\n",
    "\n",
    "1. **Exporta os dados tratados** (`interim` e `processed`);\n",
    "2. **Gera um arquivo de metadados (`meta.json`)** com a estrutura do dataset;\n",
    "3. **Cria um manifesto (`manifest.json`)** com o resumo t√©cnico da execu√ß√£o ‚Äî mem√≥ria usada, flags criadas, caminhos de sa√≠da, etc.\n",
    "\n",
    "Tudo √© salvo em caminhos padronizados e definidos dinamicamente a partir do `config`.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Configura√ß√µes e Caminhos Padr√£o\n",
    "\n",
    "Os caminhos de sa√≠da podem ser definidos no `config/defaults.json`, ou usam valores padr√£o se ausentes:\n",
    "\n",
    "| Chave | Caminho padr√£o | Descri√ß√£o |\n",
    "|--------|----------------|-----------|\n",
    "| `data_interim_file` | `data/interim/interim.parquet` | Dados intermedi√°rios tratados |\n",
    "| `data_processed_file` | `data/processed/processed.parquet` | Dados finais prontos para modelagem |\n",
    "| `meta_file` | `artifacts/metadata/dataset_meta.json` | Metadados do dataset |\n",
    "| `random_seed` | `42` (padr√£o) | Semente para reprodutibilidade |\n",
    "\n",
    "A fun√ß√£o `get_artifacts_dir(\"export\")` cria automaticamente o diret√≥rio padr√£o de exporta√ß√£o:\n",
    "\n",
    "```\n",
    "reports/artifacts/export/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Etapas principais do c√≥digo\n",
    "\n",
    "### 1Ô∏è‚É£ Exporta√ß√£o dos DataFrames\n",
    "\n",
    "```python\n",
    "OUTPUT_PROCESSED = Path(config.get(\"data_processed_file\", \"data/processed/processed.parquet\"))\n",
    "OUTPUT_INTERIM   = Path(config.get(\"data_interim_file\",   \"data/interim/interim.parquet\"))\n",
    "\n",
    "if config.get(\"export_interim\", True):\n",
    "    _save_df(df, OUTPUT_INTERIM)\n",
    "\n",
    "if config.get(\"export_processed\", True):\n",
    "    _save_df(df, OUTPUT_PROCESSED)\n",
    "```\n",
    "\n",
    "A fun√ß√£o `_save_df()` detecta automaticamente o formato pelo sufixo do arquivo:\n",
    "\n",
    "| Extens√£o | Fun√ß√£o utilizada | Compress√£o |\n",
    "|-----------|------------------|-------------|\n",
    "| `.parquet` | `to_parquet()` | Compactado (`snappy`) |\n",
    "| `.csv` | `to_csv()` | UTF-8 |\n",
    "| `.xlsx` | `to_excel()` | Excel |\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Gera√ß√£o dos Metadados (`meta.json`)\n",
    "\n",
    "Cria um registro detalhado da estrutura do dataset exportado.\n",
    "\n",
    "```python\n",
    "meta = {\n",
    "  \"dataset_name\": config.get(\"dataset_name\", \"Dataset\"),\n",
    "  \"version\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "  \"target\": target_col,\n",
    "  \"class_map\": class_map,\n",
    "  \"columns\": {\n",
    "    \"numeric\": numeric_cols,\n",
    "    \"categorical\": categorical_cols,\n",
    "    \"boolean\": boolean_cols,\n",
    "    \"ignored\": ignored_cols,\n",
    "    \"all\": all_cols\n",
    "  }\n",
    "}\n",
    "META_FILE.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "```\n",
    "\n",
    "Esse arquivo √© essencial para o N2, pois indica:\n",
    "- quais colunas s√£o num√©ricas, categ√≥ricas e booleanas;\n",
    "- qual √© o `target`;\n",
    "- quais colunas foram ignoradas;\n",
    "- o mapeamento de classes (`class_map`, se existir);\n",
    "- a vers√£o e data de exporta√ß√£o.\n",
    "\n",
    "> üí° **Dica:**  \n",
    "> voc√™ pode adicionar `meta[\"dtypes\"] = {c: str(t) for c, t in df.dtypes.items()}`  \n",
    "> para registrar os tipos exatos de cada coluna no arquivo de metadados.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Registro do Manifesto de Execu√ß√£o (`manifest.json`)\n",
    "\n",
    "O manifesto √© um **resumo t√©cnico** da sess√£o atual ‚Äî √∫til para auditoria e rastreabilidade.\n",
    "\n",
    "```python\n",
    "manifest = {\n",
    "  \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "  \"random_seed\": RANDOM_SEED,\n",
    "  \"config\": config,\n",
    "  \"memory_mb\": float(df.memory_usage(deep=True).sum() / (1024**2)),\n",
    "  \"outlier_flags\": [c for c in df.columns if c.endswith(\"_is_outlier\")],\n",
    "  \"imputed_flags\": [c for c in df.columns if c.startswith(\"was_imputed_\")],\n",
    "  \"shape\": tuple(df.shape),\n",
    "  \"exported\": {\n",
    "    \"interim\": str(OUTPUT_INTERIM),\n",
    "    \"processed\": str(OUTPUT_PROCESSED),\n",
    "    \"meta_file\": str(META_FILE)\n",
    "  }\n",
    "}\n",
    "\n",
    "(ARTIFACTS_DIR / \"manifest.json\").write_text(json.dumps(manifest, indent=2, ensure_ascii=False))\n",
    "```\n",
    "\n",
    "Campos mais importantes:\n",
    "| Campo | Descri√ß√£o |\n",
    "|--------|------------|\n",
    "| `created_at` | Data e hora da execu√ß√£o |\n",
    "| `random_seed` | Semente aleat√≥ria utilizada |\n",
    "| `memory_mb` | Tamanho em mem√≥ria do DataFrame |\n",
    "| `outlier_flags` / `imputed_flags` | Colunas criadas por outliers ou imputa√ß√µes |\n",
    "| `shape` | Dimens√£o final do dataset |\n",
    "| `exported` | Caminhos de sa√≠da dos artefatos gerados |\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ Log de conclus√£o\n",
    "\n",
    "Ao final da c√©lula, √© exibido no notebook:\n",
    "\n",
    "```\n",
    "[INFO] [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\export\n",
    "Arquivos gerados:\n",
    "- INTERIM:   data\\interim\\interim.parquet\n",
    "- PROCESSED: data\\processed\\processed.parquet\n",
    "- META:      artifacts\\metadata\\dataset_meta.json\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Boas pr√°ticas\n",
    "\n",
    "- **Vers√£o dos dados**: use o campo `\"version\"` do meta para marcar reprocessamentos.\n",
    "- **Controle de reprodutibilidade**: defina `random_seed` no config.\n",
    "- **Organiza√ß√£o**: mantenha sempre `interim`, `processed` e `meta` sob versionamento no Git.\n",
    "- **Auditoria**: o `manifest.json` √© a ‚Äúassinatura digital‚Äù da execu√ß√£o do N1.\n",
    "- **Portabilidade**: todo o caminho √© relativo √† raiz do projeto, garantindo compatibilidade com outros ambientes.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula encerra o **notebook N1**, gerando todos os artefatos necess√°rios para as etapas seguintes (EDA, modelagem e visualiza√ß√£o).  \n",
    "> Ela garante **reprodutibilidade**, **rastreamento** e **organiza√ß√£o** dos resultados, consolidando as sa√≠das do pipeline em formatos padronizados e facilmente reutiliz√°veis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0339ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:17,596 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:17,599 | INFO | [path] PROJECT_ROOT -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:17,601 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\export\n",
      "2025-11-04 05:00:17,603 | INFO | [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\export\n",
      "\n",
      "================================================================================\n",
      "üì¶  EXPORTA√á√ÉO DE ARTEFATOS ‚Äî RESUMO FINAL\n",
      "================================================================================\n",
      "üóÇÔ∏è  Dataset:        Dataset\n",
      "üéØ  Target:         Churn\n",
      "üßÆ  Linhas:         7,043\n",
      "üî¢  Num√©ricas:      62 colunas\n",
      "üî†  Categ√≥ricas:    65 colunas\n",
      "üîò  Booleanas:      49 colunas\n",
      "üßæ  Ignoradas:      0 colunas\n",
      "üß©  Todas:          128 colunas totais\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üì¶ Exporta√ß√£o de Artefatos (N1 ‚Üí N2)\n",
    "# =============================================================================\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Raiz do projeto\n",
    "PROJECT_ROOT = ud.ensure_project_root()\n",
    "logger.info(f\"[path] PROJECT_ROOT -> {PROJECT_ROOT}\")\n",
    "\n",
    "# 1) Caminhos a partir da config (com defaults) ‚Äî relativos √† raiz\n",
    "OUTPUT_PROCESSED = PROJECT_ROOT / Path(config.get(\"data_processed_file\", \"data/processed/processed.parquet\"))\n",
    "OUTPUT_INTERIM   = PROJECT_ROOT / Path(config.get(\"data_interim_file\",   \"data/interim/interim.parquet\"))\n",
    "META_FILE        = PROJECT_ROOT / Path(config.get(\"meta_file\",           \"artifacts/metadata/dataset_meta.json\"))\n",
    "\n",
    "# 2) Garante diret√≥rios\n",
    "OUTPUT_PROCESSED.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_INTERIM.parent.mkdir(parents=True, exist_ok=True)\n",
    "META_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# üëâ uso do helper para resolver o diret√≥rio de artefatos (sempre na raiz)\n",
    "ARTIFACTS_DIR = ud.get_artifacts_dir(\"export\")\n",
    "\n",
    "# 3) Salva tabelas respeitando a extens√£o (.csv / .parquet / .xlsx)\n",
    "def _save_df(df_, path_: Path):\n",
    "    ext = path_.suffix.lower()\n",
    "    if ext == \".parquet\":\n",
    "        df_.to_parquet(path_, index=False)\n",
    "    elif ext == \".csv\":\n",
    "        df_.to_csv(path_, index=False, encoding=\"utf-8\")\n",
    "    elif ext == \".xlsx\":\n",
    "        df_.to_excel(path_, index=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Extens√£o n√£o suportada: {ext}\")\n",
    "\n",
    "if config.get(\"export_interim\", True):\n",
    "    _save_df(df, OUTPUT_INTERIM)\n",
    "\n",
    "if config.get(\"export_processed\", True):\n",
    "    _save_df(df, OUTPUT_PROCESSED)\n",
    "\n",
    "# 4) Monta METADADOS para o N2 (alinhado ao config.target.name, com fallback)\n",
    "target_cfg  = config.get(\"target\", {}) or {}\n",
    "target_col  = target_cfg.get(\"name\", config.get(\"target_column\", \"target\"))\n",
    "\n",
    "all_cols = df.columns.tolist()\n",
    "ignored_cols = config.get(\"ignored_columns\", [])\n",
    "candidate_features = [c for c in all_cols if c not in ignored_cols and c != target_col]\n",
    "\n",
    "numeric_cols     = df[candidate_features].select_dtypes(include=[np.number]).columns.tolist()\n",
    "boolean_cols     = df[candidate_features].select_dtypes(include=[\"bool\", \"boolean\"]).columns.tolist()\n",
    "categorical_cols = [c for c in candidate_features if c not in numeric_cols]\n",
    "\n",
    "class_map = globals().get(\"class_map\", None)\n",
    "\n",
    "meta = {\n",
    "    \"dataset_name\": config.get(\"dataset_name\", \"Dataset\"),\n",
    "    \"version\":      datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"target\":       target_col,\n",
    "    \"class_map\":    class_map,\n",
    "    \"columns\": {\n",
    "        \"numeric\":     numeric_cols,\n",
    "        \"categorical\": categorical_cols,\n",
    "        \"boolean\":     boolean_cols,\n",
    "        \"ignored\":     ignored_cols,\n",
    "        \"all\":         all_cols\n",
    "    }\n",
    "}\n",
    "\n",
    "# enriquecer com esquema e n¬∫ de linhas\n",
    "meta[\"dtypes\"] = {c: str(t) for c, t in df.dtypes.items()}\n",
    "meta[\"rows\"]   = int(len(df))\n",
    "\n",
    "# 5) Salva META\n",
    "META_FILE.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "# üîç Verifica√ß√£o e resumo final\n",
    "_mpath = Path(META_FILE)\n",
    "_mjson = json.loads(_mpath.read_text(encoding=\"utf-8\"))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶  EXPORTA√á√ÉO DE ARTEFATOS ‚Äî RESUMO FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üóÇÔ∏è  Dataset:        {meta['dataset_name']}\")\n",
    "print(f\"üéØ  Target:         {_mjson.get('target')}\")\n",
    "print(f\"üßÆ  Linhas:         {_mjson.get('rows'):,}\")\n",
    "print(f\"üî¢  Num√©ricas:      {len(_mjson['columns']['numeric'])} colunas\")\n",
    "print(f\"üî†  Categ√≥ricas:    {len(_mjson['columns']['categorical'])} colunas\")\n",
    "print(f\"üîò  Booleanas:      {len(_mjson['columns']['boolean'])} colunas\")\n",
    "print(f\"üßæ  Ignoradas:      {len(_mjson['columns']['ignored'])} colunas\")\n",
    "print(f\"üß©  Todas:          {len(_mjson['columns']['all'])} colunas totais\")\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84490465-10de-4204-bbad-9f92a711caf4",
   "metadata": {},
   "source": [
    "# üß≠ Resumo final de sanidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "936b2846-b5be-4558-92b9-d0f2476da56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-04 05:00:18,962 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\export\n",
      "2025-11-04 05:00:18,964 | INFO | [path] artifacts_dir -> C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\export\n",
      "\n",
      "================================================================================\n",
      "‚úÖ  N1 CONCLU√çDO ‚Äî RESUMO DE SANIDADE\n",
      "================================================================================\n",
      "üìê Shape final do df:   (7043, 128)\n",
      "üéØ Target:              Churn\n",
      "üßÆ Linhas registradas:  7043\n",
      "üßæ Colunas (totais):    128\n",
      "   ‚îú‚îÄ Num√©ricas:        62\n",
      "   ‚îú‚îÄ Categ√≥ricas:      65\n",
      "   ‚îî‚îÄ Booleanas:        49\n",
      "\n",
      "üì¶ Artefatos gerados:\n",
      "   ‚îú‚îÄ INTERIM:          True | C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\data\\interim\\interim.parquet\n",
      "   ‚îú‚îÄ PROCESSED:        True | C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\data\\processed\\processed.parquet\n",
      "   ‚îú‚îÄ META:             True | C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\artifacts\\metadata\\dataset_meta.json\n",
      "   ‚îî‚îÄ MANIFEST:         True | C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\artifacts\\export\\manifest.json\n",
      "\n",
      "üß† Mem√≥ria do DF:       9.39 MB\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ‚úÖ Resumo final de sanidade do N1\n",
    "# =========================================================\n",
    "from pathlib import Path\n",
    "\n",
    "ARTIFACTS_DIR_EXPORT = ud.get_artifacts_dir(\"export\")  # garante caminho\n",
    "manifest_path = ARTIFACTS_DIR_EXPORT / \"manifest.json\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ  N1 CONCLU√çDO ‚Äî RESUMO DE SANIDADE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"üìê Shape final do df:   {df.shape}\")\n",
    "print(f\"üéØ Target:              {meta.get('target', '(desconhecido)')}\")\n",
    "print(f\"üßÆ Linhas registradas:  {meta.get('rows', '(n/a)')}\")\n",
    "print(f\"üßæ Colunas (totais):    {len(meta.get('columns', {}).get('all', []))}\")\n",
    "print(f\"   ‚îú‚îÄ Num√©ricas:        {len(meta.get('columns', {}).get('numeric', []))}\")\n",
    "print(f\"   ‚îú‚îÄ Categ√≥ricas:      {len(meta.get('columns', {}).get('categorical', []))}\")\n",
    "print(f\"   ‚îî‚îÄ Booleanas:        {len(meta.get('columns', {}).get('boolean', []))}\")\n",
    "\n",
    "print(\"\\nüì¶ Artefatos gerados:\")\n",
    "print(f\"   ‚îú‚îÄ INTERIM:          {Path(OUTPUT_INTERIM).exists()} | {OUTPUT_INTERIM}\")\n",
    "print(f\"   ‚îú‚îÄ PROCESSED:        {Path(OUTPUT_PROCESSED).exists()} | {OUTPUT_PROCESSED}\")\n",
    "print(f\"   ‚îú‚îÄ META:             {Path(META_FILE).exists()} | {META_FILE}\")\n",
    "print(f\"   ‚îî‚îÄ MANIFEST:         {manifest_path.exists()} | {manifest_path}\")\n",
    "\n",
    "try:\n",
    "    mem_mb = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "    print(f\"\\nüß† Mem√≥ria do DF:       {mem_mb:,.2f} MB\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60f7c2",
   "metadata": {},
   "source": [
    "## ‚úÖ Checkpoint\n",
    "\n",
    "- **Revisar** as colunas derivadas e decis√µes (imputa√ß√£o, outliers, codifica√ß√£o).  \n",
    "- **Documentar** no README as escolhas de neg√≥cio e justificativas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da717ec1",
   "metadata": {},
   "source": [
    "## üìé Anota√ß√µes\n",
    "\n",
    "Esta se√ß√£o pode ser usada como bloco livre para observa√ß√µes espec√≠ficas do projeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda159f-e8c4-4425-a54d-1e4c3e1c186b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
